{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('pytor1.12': conda)",
   "display_name": "Python 3.6.10 64-bit ('pytor1.12': conda)",
   "metadata": {
    "interpreter": {
     "hash": "521b0883aadebb34975bad4f964c25c8a8224771a5b887cc0070c3c89f50aff7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv file\n",
    "df = pd.read_csv('../dataset/crops_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting from pandas dataframe to numpy\n",
    "np_inputs = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[33.259373   7.030931  60.84086   ... 15.602418   6.7222724 10.1207695]\n",
      " [33.324234   6.562556  64.75895   ... 16.013498   6.084758  11.4723835]\n",
      " [33.736282   6.557421  61.573425  ... 16.430769   5.703082  11.680659 ]\n",
      " ...\n",
      " [25.8816     6.181125  30.692217  ... 53.876553  23.047926  12.743419 ]\n",
      " [24.774702   6.929148  58.6065    ... 47.295223  24.395452  11.042995 ]\n",
      " [23.613468   6.6437187 53.63108   ... 54.34586   26.842375  13.102743 ]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# inputs are from col-6 to col-13\n",
    "inputs = np_inputs[:, 6:14]\n",
    "inputs = np.array(inputs, dtype='float32')\n",
    "\n",
    "print(inputs)\n",
    "\n",
    "\n",
    "# convert output crops to binary encoded labels\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(np_inputs[:,14])\n",
    "outputs = lb.transform(np_inputs[:,14])\n",
    "\n",
    "outputs = np.array(outputs, dtype='float32')\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[33.2594,  7.0309, 60.8409,  ..., 15.6024,  6.7223, 10.1208],\n        [33.3242,  6.5626, 64.7589,  ..., 16.0135,  6.0848, 11.4724],\n        [33.7363,  6.5574, 61.5734,  ..., 16.4308,  5.7031, 11.6807],\n        ...,\n        [25.8816,  6.1811, 30.6922,  ..., 53.8766, 23.0479, 12.7434],\n        [24.7747,  6.9291, 58.6065,  ..., 47.2952, 24.3955, 11.0430],\n        [23.6135,  6.6437, 53.6311,  ..., 54.3459, 26.8424, 13.1027]])\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [1., 0., 0.,  ..., 0., 0., 0.],\n        [1., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 1.],\n        [0., 0., 0.,  ..., 0., 0., 1.],\n        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# converting numpy array into torch tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "outputs = torch.from_numpy(outputs)\n",
    "\n",
    "print(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "121081\n(tensor([[33.2594,  7.0309, 60.8409, 32.7850, 37.2703, 15.6024,  6.7223, 10.1208],\n        [33.3242,  6.5626, 64.7589, 29.3024, 36.9567, 16.0135,  6.0848, 11.4724],\n        [33.7363,  6.5574, 61.5734, 29.1465, 36.2751, 16.4308,  5.7031, 11.6807]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "ds = TensorDataset(inputs,outputs)\n",
    "print(len(ds))\n",
    "print(ds[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(96865, 24216)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_ds, valid_ds = random_split(ds, [96865, 24216])\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1514\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds , batch_size , shuffle=True )\n",
    "val_loader = DataLoader(valid_ds , batch_size)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# defining neural network parameteres\n",
    "input_nodes = 8\n",
    "hidden1_nodes = 64\n",
    "hidden2_nodes = 64\n",
    "output_nodes = 29\n",
    "\n",
    "# creating neural net\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = nn.Linear(input_nodes, hidden1_nodes)\n",
    "        self.hidden1 = nn.Linear(hidden1_nodes, hidden2_nodes)\n",
    "        self.hidden2 = nn.Linear(hidden2_nodes, output_nodes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1737,  0.2860,  0.3418,  0.3165, -0.2222,  0.0916, -0.0760, -0.0645],\n",
       "         [-0.1592, -0.3264, -0.0261, -0.1733,  0.2720, -0.2364,  0.1779,  0.2441],\n",
       "         [-0.2995,  0.1391,  0.3227,  0.1141, -0.0889,  0.3007,  0.2142, -0.0777],\n",
       "         [-0.3493, -0.0545,  0.1866, -0.2905,  0.1551, -0.2486,  0.2347,  0.2071],\n",
       "         [-0.1365,  0.3288, -0.2804, -0.0777, -0.1762,  0.0796,  0.2921, -0.2484],\n",
       "         [-0.2762, -0.2739,  0.0439,  0.2465,  0.1861,  0.1913,  0.2362, -0.3021],\n",
       "         [ 0.2912, -0.1736, -0.2331,  0.1485, -0.2144, -0.1230,  0.2357,  0.0167],\n",
       "         [ 0.0027, -0.2358, -0.2927,  0.1545, -0.2930,  0.0097,  0.0464,  0.1298],\n",
       "         [ 0.0670, -0.3334,  0.1535,  0.1283,  0.2919,  0.0885, -0.3315, -0.0403],\n",
       "         [ 0.0873,  0.3246, -0.2126, -0.1473, -0.1392,  0.2308,  0.0449, -0.2419],\n",
       "         [ 0.1537,  0.0982, -0.2386,  0.3435,  0.3207, -0.1766,  0.0199, -0.2200],\n",
       "         [ 0.3154, -0.3310,  0.1581,  0.1463, -0.3118, -0.0217, -0.1670,  0.1338],\n",
       "         [-0.1128,  0.2125, -0.3005,  0.2653, -0.1127,  0.2095, -0.2630,  0.0421],\n",
       "         [-0.3286,  0.3030,  0.0022, -0.0892, -0.1498,  0.2436,  0.3192, -0.0443],\n",
       "         [ 0.3164,  0.1897, -0.2739, -0.3223,  0.1345, -0.0379,  0.0708,  0.1055],\n",
       "         [-0.0527, -0.0826,  0.1738, -0.0814, -0.1142,  0.1037, -0.2056, -0.1931],\n",
       "         [ 0.1031,  0.0540,  0.0986, -0.0763, -0.0531,  0.2479,  0.0250, -0.1515],\n",
       "         [-0.3395,  0.1270,  0.1103, -0.1666,  0.0027, -0.3020,  0.0262,  0.2808],\n",
       "         [ 0.2789, -0.3293,  0.0426, -0.3315, -0.1756,  0.2242,  0.2581,  0.2269],\n",
       "         [-0.2072, -0.2741,  0.3170, -0.1639,  0.2798,  0.3530,  0.1238,  0.0168],\n",
       "         [ 0.2771, -0.1966, -0.3075,  0.1370,  0.2401,  0.1367, -0.1105,  0.2913],\n",
       "         [ 0.1790, -0.2165, -0.0802,  0.2046,  0.0220,  0.2640, -0.1819,  0.2857],\n",
       "         [ 0.1823,  0.0495,  0.1043,  0.1332, -0.1704, -0.2265,  0.0720,  0.1728],\n",
       "         [ 0.1199, -0.0827,  0.1243, -0.0913, -0.1449, -0.2217,  0.1500, -0.2001],\n",
       "         [-0.1503, -0.1034,  0.3036,  0.0060,  0.2830,  0.1514, -0.0009, -0.1566],\n",
       "         [ 0.2488, -0.1415,  0.1658, -0.0164,  0.2621, -0.3192, -0.2580, -0.0193],\n",
       "         [-0.1376,  0.3225, -0.3412,  0.2892,  0.2193,  0.1733,  0.3180,  0.1392],\n",
       "         [-0.0626,  0.1587,  0.1773,  0.2407,  0.0588,  0.2036, -0.3127, -0.3284],\n",
       "         [ 0.0500, -0.1959,  0.3433,  0.3406, -0.2904, -0.1687,  0.1819, -0.2263],\n",
       "         [ 0.1875,  0.2577,  0.0665,  0.1948, -0.1036, -0.0393,  0.2393,  0.1905],\n",
       "         [-0.2554, -0.2966, -0.0800,  0.1604,  0.3287,  0.1731,  0.2810, -0.0458],\n",
       "         [-0.0028,  0.0331, -0.2320, -0.2295,  0.1998,  0.1825, -0.0899,  0.0890],\n",
       "         [ 0.3044,  0.1138, -0.3189, -0.3534,  0.2149, -0.1257, -0.2764,  0.2365],\n",
       "         [-0.2894,  0.1619,  0.0247,  0.1241, -0.2067,  0.1530, -0.3223,  0.2678],\n",
       "         [-0.3439, -0.1786, -0.0101, -0.2319,  0.1183,  0.1905, -0.2880, -0.0534],\n",
       "         [-0.2652,  0.0966, -0.3360, -0.1458,  0.0452,  0.1863, -0.3405, -0.3380],\n",
       "         [ 0.1750,  0.3132, -0.2472, -0.3361, -0.0037,  0.2887, -0.1483,  0.2670],\n",
       "         [-0.3039,  0.1759,  0.1848,  0.1871, -0.2726, -0.1692, -0.2320, -0.3245],\n",
       "         [-0.2554, -0.0369,  0.0883,  0.0937,  0.0518,  0.1613,  0.0944,  0.0352],\n",
       "         [ 0.2238, -0.0235,  0.0715,  0.1885, -0.3251,  0.0385,  0.2957, -0.1718],\n",
       "         [ 0.1764,  0.2146,  0.1364, -0.0451, -0.0190, -0.1825, -0.1304, -0.3470],\n",
       "         [ 0.0401,  0.2797,  0.0019,  0.0274, -0.0242, -0.2896, -0.0109,  0.1989],\n",
       "         [ 0.0861,  0.1736, -0.0503,  0.2174,  0.0343, -0.2432, -0.1361, -0.1916],\n",
       "         [ 0.2719, -0.0200,  0.2808,  0.1304, -0.3457, -0.0630, -0.0095, -0.0458],\n",
       "         [-0.2547, -0.0121,  0.0633, -0.3405, -0.2249, -0.2801, -0.2701,  0.1723],\n",
       "         [-0.1846,  0.1521, -0.1287,  0.0205, -0.2658,  0.0919, -0.2383, -0.2932],\n",
       "         [-0.2157, -0.1687,  0.2821, -0.2847,  0.1183, -0.3456,  0.2512, -0.0312],\n",
       "         [ 0.2857,  0.2443, -0.0537, -0.0265, -0.3287,  0.1942,  0.0975,  0.2947],\n",
       "         [-0.1402, -0.2456,  0.0416,  0.1562,  0.2387, -0.3329,  0.2413, -0.1227],\n",
       "         [ 0.1916, -0.3168, -0.1783,  0.2772,  0.0307,  0.1228,  0.0528,  0.2219],\n",
       "         [-0.0722, -0.3261, -0.1586,  0.2686,  0.0206, -0.0689, -0.0883,  0.0009],\n",
       "         [ 0.1579,  0.0693, -0.1169,  0.1460,  0.1676,  0.2879, -0.0986, -0.3001],\n",
       "         [ 0.1448, -0.1260, -0.3180,  0.1717,  0.1609, -0.0427, -0.3283,  0.1126],\n",
       "         [-0.2584,  0.1743,  0.0546,  0.1935, -0.2640, -0.2324,  0.2238,  0.1767],\n",
       "         [-0.1736,  0.2101,  0.2608, -0.0055, -0.2120, -0.2676,  0.0059, -0.3060],\n",
       "         [ 0.2847, -0.2876, -0.0116,  0.1418, -0.2530,  0.3397,  0.2630,  0.3249],\n",
       "         [-0.1788,  0.2989,  0.2164,  0.0132,  0.0218, -0.2146,  0.3229, -0.1601],\n",
       "         [ 0.0393, -0.2457, -0.0393,  0.3448,  0.0676, -0.2118,  0.0192,  0.0679],\n",
       "         [ 0.1320, -0.3448, -0.1282,  0.3262, -0.2181, -0.2293,  0.1876,  0.2769],\n",
       "         [-0.0329,  0.1303,  0.1031, -0.0653, -0.2659, -0.2602, -0.2910,  0.1212],\n",
       "         [ 0.2283, -0.1212,  0.2611, -0.2537,  0.3425,  0.1866,  0.0162,  0.0655],\n",
       "         [-0.2749, -0.1043,  0.1517, -0.1095,  0.1106, -0.1272, -0.2510, -0.2968],\n",
       "         [-0.2410,  0.1276,  0.0759,  0.2848,  0.1115, -0.2538,  0.3368, -0.2691],\n",
       "         [ 0.1725,  0.2684, -0.0508, -0.0343,  0.0801, -0.0656, -0.0233,  0.3124]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2935, -0.0798,  0.1287, -0.1927, -0.1107,  0.3235,  0.1479,  0.1670,\n",
       "         -0.2357, -0.2081, -0.1427,  0.0185,  0.1293,  0.1775,  0.1373, -0.3143,\n",
       "         -0.0099, -0.2635,  0.3165,  0.1827,  0.0143,  0.0133,  0.2000, -0.1724,\n",
       "          0.0304,  0.2904,  0.0244, -0.3090, -0.1589,  0.0178, -0.2125, -0.0500,\n",
       "         -0.0378, -0.2303, -0.0220,  0.3034, -0.3313,  0.1539, -0.0733,  0.1725,\n",
       "          0.0775, -0.2710,  0.2775, -0.3122,  0.2021, -0.3382, -0.1999,  0.2605,\n",
       "         -0.0091,  0.0780,  0.1527,  0.2418, -0.2525, -0.1599,  0.2186, -0.2144,\n",
       "          0.1238, -0.2837, -0.1913,  0.0562, -0.3168, -0.1294,  0.2962,  0.2453],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0735,  0.1044,  0.0301,  ...,  0.0812,  0.1166, -0.0292],\n",
       "         [ 0.0156,  0.1022, -0.0703,  ..., -0.0462, -0.0398, -0.0669],\n",
       "         [ 0.0086,  0.0023, -0.0725,  ..., -0.0598, -0.0778,  0.1119],\n",
       "         ...,\n",
       "         [ 0.0718, -0.0836, -0.0881,  ...,  0.1239, -0.0205, -0.0419],\n",
       "         [ 0.0039, -0.0869, -0.1073,  ..., -0.0614,  0.0870, -0.0592],\n",
       "         [-0.1235,  0.0660, -0.0760,  ...,  0.1174,  0.0792, -0.0261]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0904,  0.0529,  0.0471, -0.0314, -0.0937,  0.0190,  0.0818,  0.0422,\n",
       "          0.0761, -0.0679,  0.1026, -0.1215, -0.0274,  0.0549,  0.0072,  0.1243,\n",
       "          0.1129,  0.1081, -0.0266,  0.0788,  0.0620,  0.1096,  0.0383, -0.1100,\n",
       "         -0.0590,  0.1097, -0.1100,  0.0305,  0.1053,  0.0255,  0.0125, -0.0718,\n",
       "          0.1230,  0.1083,  0.0028, -0.0312, -0.0560, -0.0700,  0.1041, -0.1076,\n",
       "         -0.0478,  0.0203, -0.1240,  0.0215, -0.1180,  0.1055,  0.0448, -0.1044,\n",
       "         -0.0869, -0.1021, -0.0972, -0.1204, -0.0014,  0.0670,  0.0409,  0.0419,\n",
       "          0.0508, -0.0721, -0.0134,  0.0515, -0.1189, -0.1181, -0.0954, -0.1175],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0097,  0.1065,  0.0687,  ...,  0.0448,  0.1140, -0.0113],\n",
       "         [ 0.1000,  0.1103,  0.1083,  ...,  0.0186,  0.0105,  0.0533],\n",
       "         [-0.0215, -0.0338, -0.1230,  ...,  0.1032, -0.1064, -0.0847],\n",
       "         ...,\n",
       "         [-0.1179,  0.0893, -0.0299,  ..., -0.0110,  0.0168, -0.0288],\n",
       "         [ 0.1068,  0.0459,  0.0515,  ...,  0.0153,  0.0845, -0.0293],\n",
       "         [-0.0324, -0.1127,  0.0100,  ..., -0.0373,  0.0539,  0.0418]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0003, -0.0045, -0.0440,  0.0395, -0.1206, -0.0294,  0.1065,  0.0493,\n",
       "         -0.0226,  0.0303,  0.1203,  0.1002,  0.0464,  0.1089,  0.0790, -0.0656,\n",
       "         -0.0307, -0.0956,  0.1069, -0.0386,  0.0980,  0.0391, -0.0200,  0.0345,\n",
       "          0.0877,  0.0209,  0.0630,  0.0776, -0.0586], requires_grad=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model = Model()\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_dict={}\n",
    "def train(model,epochs,train_batch,valid_batch,lr,opt_fn=torch.optim.SGD):\n",
    "    opt = opt_fn(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        loss_dict[epoch] = 0\n",
    "        i = 0\n",
    "        for input_part, output_part in train_batch:\n",
    "            i+=1\n",
    "            output = model(input_part)\n",
    "            loss = F.mse_loss(output,output_part)\n",
    "            loss_dict[epoch]+=loss\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            #print(\"Done with {0} part of {1}/{2}\".format(i,epoch,epochs))\n",
    "        loss_dict[epoch]/1514\n",
    "        print(\"For epoch {0} avg_loss = {1}\".format(epoch,loss_dict[epoch]))\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For epoch 0 avg_loss = 47.72978973388672\n",
      "For epoch 1 avg_loss = 40.6528434753418\n",
      "For epoch 2 avg_loss = 35.86530303955078\n",
      "For epoch 3 avg_loss = 31.41950035095215\n",
      "For epoch 4 avg_loss = 28.898696899414062\n",
      "For epoch 5 avg_loss = 26.880281448364258\n",
      "For epoch 6 avg_loss = 25.05280303955078\n",
      "For epoch 7 avg_loss = 22.525779724121094\n",
      "For epoch 8 avg_loss = 20.965139389038086\n",
      "For epoch 9 avg_loss = 18.899246215820312\n",
      "For epoch 10 avg_loss = 18.009607315063477\n",
      "For epoch 11 avg_loss = 17.379968643188477\n",
      "For epoch 12 avg_loss = 16.88858985900879\n",
      "For epoch 13 avg_loss = 16.5014705657959\n",
      "For epoch 14 avg_loss = 16.183528900146484\n",
      "For epoch 15 avg_loss = 15.915989875793457\n",
      "For epoch 16 avg_loss = 15.694823265075684\n",
      "For epoch 17 avg_loss = 15.50417709350586\n",
      "For epoch 18 avg_loss = 15.338512420654297\n",
      "For epoch 19 avg_loss = 15.19038200378418\n",
      "For epoch 20 avg_loss = 15.056122779846191\n",
      "For epoch 21 avg_loss = 14.926414489746094\n",
      "For epoch 22 avg_loss = 14.791873931884766\n",
      "For epoch 23 avg_loss = 14.641607284545898\n",
      "For epoch 24 avg_loss = 14.483238220214844\n",
      "For epoch 25 avg_loss = 14.343090057373047\n",
      "For epoch 26 avg_loss = 14.233420372009277\n",
      "For epoch 27 avg_loss = 14.14404582977295\n",
      "For epoch 28 avg_loss = 14.076628684997559\n",
      "For epoch 29 avg_loss = 14.013920783996582\n",
      "For epoch 30 avg_loss = 13.95337963104248\n",
      "For epoch 31 avg_loss = 13.894721031188965\n",
      "For epoch 32 avg_loss = 13.837409973144531\n",
      "For epoch 33 avg_loss = 13.77702522277832\n",
      "For epoch 34 avg_loss = 13.727048873901367\n",
      "For epoch 35 avg_loss = 13.67901611328125\n",
      "For epoch 36 avg_loss = 13.6366548538208\n",
      "For epoch 37 avg_loss = 13.592004776000977\n",
      "For epoch 38 avg_loss = 13.549299240112305\n",
      "For epoch 39 avg_loss = 13.50748062133789\n",
      "For epoch 40 avg_loss = 13.472867012023926\n",
      "For epoch 41 avg_loss = 13.425602912902832\n",
      "For epoch 42 avg_loss = 13.368790626525879\n",
      "For epoch 43 avg_loss = 13.281448364257812\n",
      "For epoch 44 avg_loss = 13.13353443145752\n",
      "For epoch 45 avg_loss = 12.989422798156738\n",
      "For epoch 46 avg_loss = 12.89649772644043\n",
      "For epoch 47 avg_loss = 12.838105201721191\n",
      "For epoch 48 avg_loss = 12.799384117126465\n",
      "For epoch 49 avg_loss = 12.767719268798828\n",
      "For epoch 50 avg_loss = 12.742782592773438\n",
      "For epoch 51 avg_loss = 12.719622611999512\n",
      "For epoch 52 avg_loss = 12.704795837402344\n",
      "For epoch 53 avg_loss = 12.684112548828125\n",
      "For epoch 54 avg_loss = 12.667926788330078\n",
      "For epoch 55 avg_loss = 12.653643608093262\n",
      "For epoch 56 avg_loss = 12.639789581298828\n",
      "For epoch 57 avg_loss = 12.628700256347656\n",
      "For epoch 58 avg_loss = 12.613377571105957\n",
      "For epoch 59 avg_loss = 12.602231979370117\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "lr = 1e-2\n",
    "\n",
    "history = train(model, epochs, train_loader, val_loader, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 368.925 248.518125\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-10-24T02:44:45.480059</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 368.925 248.518125 \nL 368.925 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 361.725 224.64 \nL 361.725 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mc1af3ea481\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.143182\" xlink:href=\"#mc1af3ea481\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(38.961932 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"93.730239\" xlink:href=\"#mc1af3ea481\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <g transform=\"translate(87.367739 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"145.317296\" xlink:href=\"#mc1af3ea481\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <g transform=\"translate(138.954796 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"196.904353\" xlink:href=\"#mc1af3ea481\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30 -->\n      <g transform=\"translate(190.541853 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"248.49141\" xlink:href=\"#mc1af3ea481\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40 -->\n      <g transform=\"translate(242.12891 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"300.078467\" xlink:href=\"#mc1af3ea481\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50 -->\n      <g transform=\"translate(293.715967 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"351.665524\" xlink:href=\"#mc1af3ea481\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 60 -->\n      <g transform=\"translate(345.303024 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m0060a38021\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0060a38021\" y=\"201.263443\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 205.062662)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0060a38021\" y=\"173.127025\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 176.926244)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0060a38021\" y=\"144.990608\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 148.789827)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0060a38021\" y=\"116.85419\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 120.653409)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0060a38021\" y=\"88.717772\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 35 -->\n      <g transform=\"translate(7.2 92.516991)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0060a38021\" y=\"60.581355\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 40 -->\n      <g transform=\"translate(7.2 64.380574)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m0060a38021\" y=\"32.444937\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 45 -->\n      <g transform=\"translate(7.2 36.244156)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pdb5a50d927)\" d=\"M 42.143182 17.083636 \nL 47.301888 56.90762 \nL 52.460593 83.848467 \nL 57.619299 108.866259 \nL 62.778005 123.051535 \nL 67.93671 134.409731 \nL 73.095416 144.69347 \nL 78.254122 158.913747 \nL 83.412827 167.695912 \nL 88.571533 179.321279 \nL 93.730239 184.327529 \nL 98.888945 187.870685 \nL 104.04765 190.635813 \nL 109.206356 192.814243 \nL 114.365062 194.60339 \nL 119.523767 196.108908 \nL 124.682473 197.353476 \nL 129.841179 198.426296 \nL 134.999884 199.358538 \nL 140.15859 200.19211 \nL 145.317296 200.947624 \nL 150.476002 201.67753 \nL 155.634707 202.434628 \nL 160.793413 203.280221 \nL 165.952119 204.171408 \nL 171.110824 204.960062 \nL 176.26953 205.577204 \nL 181.428236 206.08014 \nL 186.586941 206.459515 \nL 191.745647 206.81239 \nL 196.904353 207.153073 \nL 202.063059 207.483161 \nL 207.221764 207.805667 \nL 212.38047 208.145469 \nL 217.539176 208.4267 \nL 222.697881 208.696994 \nL 227.856587 208.935373 \nL 233.015293 209.186631 \nL 238.173998 209.426948 \nL 243.332704 209.662273 \nL 248.49141 209.857053 \nL 253.650116 210.123022 \nL 258.808821 210.442721 \nL 263.967527 210.93422 \nL 269.126233 211.766574 \nL 274.284938 212.577531 \nL 279.443644 213.100447 \nL 284.60235 213.429038 \nL 289.761055 213.646933 \nL 294.919761 213.82512 \nL 300.078467 213.965445 \nL 305.237173 214.095773 \nL 310.395878 214.179208 \nL 315.554584 214.295598 \nL 320.71329 214.38668 \nL 325.871995 214.467056 \nL 331.030701 214.545016 \nL 336.189407 214.607419 \nL 341.348112 214.693644 \nL 346.506818 214.756364 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 361.725 224.64 \nL 361.725 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 361.725 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 361.725 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pdb5a50d927\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeOklEQVR4nO3deZScdZ3v8fe3qnrfO91Jegl0FiAmLAkGRMFR46gMLizjMHocL86oXM/ouXjH68K95171eGZxxis6zlyPKAIz43UZhMEbRS+yiOAdoEMWEhJIIAnppJPuLJ3el6r+3j/q6aYTElLdXdVPP1Wf1zl16tmq6vuDyqee/j2/53nM3RERkeiJhV2AiIjMjAJcRCSiFOAiIhGlABcRiSgFuIhIRCXm8sMaGhq8ra1tLj9SRCTyNm7ceMTdG09dPqcB3tbWRnt7+1x+pIhI5JnZvtMtVxeKiEhEKcBFRCJKAS4iElEKcBGRiFKAi4hElAJcRCSiFOAiIhEViQB/eOdh/teju8MuQ0RkXolEgD++6yjfemg3una5iMgrIhHgS+rLGBpLcXRgNOxSRETmjWgEeF05AC8fGwy5EhGR+SMaAV6fDvD9CnARkUkRCfAyADqOD4VciYjI/BGJAC8vTtBQWaw9cBGRKSIR4ACtdeXsP64AFxGZEJkAX1Jfzv5j6kIREZkQnQCvK+NgzxDJ1HjYpYiIzAvRCfD6cpLjTueJ4bBLERGZFyIT4OdMDCVUP7iICBChAJ84madD/eAiIsA0AtzM4ma2ycw2BPN3mdkeM9scPNbkrEqgqbaUmGkPXERkwnTuSn8LsAOonrLss+5+T3ZLOr2ieIymmjKNBRcRCWS0B25mrcC7ge/ltpzXtqS+jP06G1NEBMi8C+UbwOeAU8fw/aWZbTWz28ysJKuVncaSunJd0EpEJHDWADez9wBd7r7xlFW3AiuBy4B64PNneP3NZtZuZu3d3d2zKvac+nK6+0YYHkvN6n1ERPJBJnvgVwLvM7O9wI+A9Wb2L+7e6WkjwJ3A5ad7sbvf7u7r3H1dY2PjrIqduCphhw5kioicPcDd/VZ3b3X3NuADwMPu/idm1gRgZgZcB2zLZaHwylUJdUq9iMj0RqGc6gdm1ggYsBn4RFYqeg0TY8E1lFBEZJoB7u6PAo8G0+tzUM9raqwqoSQR01BCEREidCYmgJnRWlemLhQRESIW4JAeiaKhhCIiEQzwJfW6sYOICEQxwOvK6RtOcmJwLOxSRERCFb0AnxhKqL1wESlwkQvw1omhhOoHF5ECF7kAX6IbO4iIABEM8JqyImrKijSUUEQKXuQCHNL94BpKKCKFLpoBXqehhCIi0Qzw+nI6jg8xPu5hlyIiEppoBnhdGaPJcbr7R8IuRUQkNJEM8NZ6DSUUEYlkgOuysiIiEQ3w1jrd2EFEJJIBXloUZ1F1iYYSikhBi2SAQzCUUAEuIgUsugEeDCUUESlU0Q3wujI6TwwxmhwPuxQRkVBENsCXNVYy7rDnyEDYpYiIhCLjADezuJltMrMNwfxSM3vSzHab2Y/NrDh3Zb7aquZqALYfPDGXHysiMm9MZw/8FmDHlPmvAre5+wrgOPDRbBZ2NssaKihJxNh+sHcuP1ZEZN7IKMDNrBV4N/C9YN6A9cA9wSZ3A9floL4zSsRjrGyq1h64iBSsTPfAvwF8Dpg4YrgA6HH3ZDDfAbSc7oVmdrOZtZtZe3d392xqfZXVzdU8d7AXd13USkQKz1kD3MzeA3S5+8aZfIC73+7u69x9XWNj40ze4oxWN1fTO5zUcEIRKUiJDLa5EnifmV0DlALVwDeBWjNLBHvhrcCB3JV5equba4D0gcyJW62JiBSKs+6Bu/ut7t7q7m3AB4CH3f1DwCPA+4PNbgLuz1mVZ7BycRXxmOlApogUpNmMA/888Bdmtpt0n/gd2Skpc6VFcZY3VijARaQgZdKFMsndHwUeDaZfAi7PfknTc2FzDU+8eCTsMkRE5lxkz8ScsKq5msO9IxzR3XlEpMBEPsBfOZCpbhQRKSyRD/CJU+q3HdAJPSJSWCIf4DVlRSypL+M57YGLSIGJfIADrG6q0Sn1IlJw8iPAm6vZe3SQvuGxsEsREZkz+RHgLel+8B2dfSFXIiIyd/IjwKecUi8iUijyIsAXVpXQUFmsoYQiUlDyIsDNjFXNNQpwESkoeRHgkD6QuetwHyPJVNiliIjMibwK8OS4s+twf9iliIjMiTwKcB3IFJHCkjcBfm59OZUlCfWDi0jByJsAj8WM1zVVKcBFpGDkTYBDuhtlR2cvqXHd5FhE8l9eBfiq5moGR1PsPToQdikiIjmXVwF+YXAgU5eWFZFCkFcBfv6iSkqLYmzZrwAXkfx31gA3s1Ize8rMtpjZdjP7crD8LjPbY2abg8eanFd7Fol4jNXNNWzt6Am7FBGRnMvkpsYjwHp37zezIuBxM3sgWPdZd78nd+VN38WtNfzwqZdJpsZJxPPqDwwRkZOcNeE8beL0xqLgMW+HeVzcWsPw2Di7unRGpojkt4x2Uc0sbmabgS7gQXd/Mlj1l2a21cxuM7OSM7z2ZjNrN7P27u7u7FT9Gi5urQXg2Q71g4tIfssowN095e5rgFbgcjO7ELgVWAlcBtQDnz/Da29393Xuvq6xsTE7Vb+GpQsqqCpJsEX94CKS56bVSezuPcAjwNXu3hl0r4wAdwKX56C+aYvFjItaa9iqPXARyXOZjEJpNLPaYLoMeAew08yagmUGXAdsy12Z03Nxay07D/Xq0rIiktcyGYXSBNxtZnHSgf8Td99gZg+bWSNgwGbgE7krc3oubq1hLOXs7OzjkiW1YZcjIpITZw1wd98KrD3N8vU5qSgLLm5Nn5G5taNHAS4ieSsvB0q31JaxoKKYLeoHF5E8lpcBbmZc3KozMkUkv+VlgEP6QOburn4GRpJhlyIikhN5HOA1jDu6wYOI5K08DvBaAHWjiEjeytsAb6wqobmmVAcyRSRv5W2AQ3ovXHvgIpKv8jvAl9Sw7+ggJwbHwi5FRCTr8jvAW2oB2HqgJ9Q6RERyIa8D/KLJMzLVDy4i+SevA7ymrIilDRVs2d8TdikiIlmX1wEO6fHgz+ou9SKShwogwGvpPDFMV99w2KWIiGRVAQR4uh98y37thYtIfsn7AL+opYbKkgQPPnco7FJERLIq7wO8tCjO1Rcu5oFnDzE8pjv0iEj+yPsAB7jh0hb6RpI8+NzhsEsREcmaggjwK5YuoLmmlPs2HQi7FBGRrCmIAI/FjGvXtvCbF7o50j8SdjkiIlmRyV3pS83sKTPbYmbbzezLwfKlZvakme02sx+bWXHuy525G9a2kBp3frb5YNiliIhkRSZ74CPAene/BFgDXG1mVwBfBW5z9xXAceCjOasyC85bVMWFLdXqRhGRvHHWAPe0/mC2KHg4sB64J1h+N3BdLgrMpuvXtvLsgRPs7uoLuxQRkVnLqA/czOJmthnoAh4EXgR63H3ihpMdQMsZXnuzmbWbWXt3d3cWSp65913STDxm3PuM9sJFJPoyCnB3T7n7GqAVuBxYmekHuPvt7r7O3dc1NjbOrMosaawq4c3nNXD/5oOMj3uotYiIzNa0RqG4ew/wCPBGoNbMEsGqViASu7XXr23hQM8QT+45FnYpIiKzkskolEYzqw2my4B3ADtIB/n7g81uAu7PUY1Z9c5Vi6ksSXDfpo6wSxERmZVM9sCbgEfMbCvwNPCgu28APg/8hZntBhYAd+SuzOwpK9ap9SKSHxJn28DdtwJrT7P8JdL94ZFzw9oW7tnYwYPPHea9lzSHXY6IyIwUxJmYp7pi2QJaasv453/fF3YpIiIzVpABHosZf3bVUp7ac4zNut2aiERUQQY4wB9ftoSq0gTffeylsEsREZmRgg3wypIEf3LFuTywrZOXjw6GXY6IyLQVbIADfORNbcRjxvef2BN2KSIi01bQAb6oupRr17Tw46f30zM4GnY5IiLTUtABDvDxNy9jaCzFv2hEiohETMEH+AWLq3jrBY3c9bt9OrFHRCKl4AMc4OY3L+NI/wj3b47E5VxERAAFOABvXL6A1c3V3P7YS7pKoYhEhgIcMDNu/r1lvNg9wCPPd4VdjohIRhTggWsuaqKltoxvP/oi7toLF5H5TwEeKIrH+MRbltG+7zhP7D4adjkiImelAJ/ixsuW0FRTyjd+/YL2wkVk3lOAT1GSiPPnb1tB+77jPL77SNjliIi8JgX4KW5c10pzTSnf+PUu7YWLyLymAD/FxF74xn3H+e0u7YWLyPylAD+NP5rcC1dfuIjMXwrw05jYC3/m5R7thYvIvJXJXemXmNkjZvacmW03s1uC5V8yswNmtjl4XJP7cufOjeuW0FxTym3aCxeReSqTPfAk8Bl3XwVcAXzSzFYF625z9zXB4xc5qzIExYkYn1y/gk0v9/CY9sJFZB46a4C7e6e7PxNM9wE7gJZcFzYf/NHrl9BSW8bfP7Qr7FJERF5lWn3gZtYGrAWeDBZ9ysy2mtn3zazuDK+52czazay9u7t7dtXOseJEjI+8qY2N+47zYnd/2OWIiJwk4wA3s0rgp8Cn3b0X+DawHFgDdAL/83Svc/fb3X2du69rbGycfcVz7No1zcQM7ntGl5oVkfklowA3syLS4f0Dd78XwN0Pu3vK3ceB7wKX567M8CysLuXKFQ3ct+mALjUrIvNKJqNQDLgD2OHuX5+yvGnKZtcD27Jf3vxww6UtHOgZon3f8bBLERGZlMke+JXAh4H1pwwZ/Fsze9bMtgJvA/5zLgsN07tWL6a8OM59mzrCLkVEZFLibBu4++OAnWZVXg0bfC3lxQmuXr2YDVs7+eJ7V1NaFA+7JBERnYmZqesvbaFvOMnDO3XHHhGZHxTgGXrT8gYWVZdwr0ajiMg8oQDPUDxmXLumhUef7+LYwGjY5YiIKMCn47o1LSTHnQ1bD4ZdioiIAnw6VjVXs3JxlbpRRGReUIBP0/VrW9i8v4eXdGq9iIRMAT5N165pwQz+bbO6UUQkXArwaVpcU8qVyxu4b1MHKZ1aLyIhUoDPwIfecA77jw3x46f3h12KiBQwBfgMXH3hYi5fWs/f/WonJwbHwi5HRAqUAnwGzIwvvXc1J4bG+PqDz4ddjogUKAX4DK1qruZDbziXf/73few81Bt2OSJSgBTgs/CZd55PdVkRX7x/u258LCJzTgE+C7XlxfyXd17Ak3uO8fNnO8MuR0QKjAJ8lj54+Tmsaqrmr36+g8HRZNjliEgBUYDPUjxmfPna1Rw8Mcy3H30x7HJEpIAowLPgsrZ6rl3TzHcee4kDPUNhlyMiBUIBniWffdcFpMadu57YE3YpIlIgFOBZ0lpXzh9cuJgfPbWf/hH1hYtI7mVyV/olZvaImT1nZtvN7JZgeb2ZPWhmu4LnutyXO7997M3L6BtJ8hOdYi8icyCTPfAk8Bl3XwVcAXzSzFYBXwAecvfzgIeC+YK2Zkktrz+3jjt/t0cXuhKRnDtrgLt7p7s/E0z3ATuAFuBa4O5gs7uB63JUY6R87Kql7D82xIPPHQq7FBHJc9PqAzezNmAt8CSwyN0nzl45BCw6w2tuNrN2M2vv7u6eTa2R8M7Vi2mtK+OOx3UwU0RyK+MAN7NK4KfAp939pIt/ePo88tP2Gbj77e6+zt3XNTY2zqrYKIjHjD+9cilP7z3Olv09YZcjInksowA3syLS4f0Dd783WHzYzJqC9U1AV25KjJ4b17VSVZLQXriI5FQmo1AMuAPY4e5fn7LqZ8BNwfRNwP3ZLy+aqkqL+OPLlvDzZzs5qBN7RCRHMtkDvxL4MLDezDYHj2uAvwHeYWa7gN8P5iXwkSvbcHfu/t3esEsRkTyVONsG7v44YGdY/fbslpM/0if2NPG/n3qZ//T286goOet/ahGRadGZmDn0sTcvpW84yWd+soXR5HjY5YhInlGA59Dac+r47+9ZxS+3H+LPf7CRkWQq7JJEJI8owHPso1ct5SvXXcivd3Tx8X/ayPCYQlxEskMBPgc+fMW5/O0fXsxvd3Xzp3c+rRs/iEhWKMDnyI2XLeHrN17Ck3uOctP3n6JveCzskkQk4hTgc+j6ta1864OXsunlHt7994/z9N5jYZckIhGmAJ9j7764iR/dfAUAN37n//HXD+zQwU0RmREFeAjWtdXzwC1v5oOXn8N3fvMS7/vWE2w/eCLsskQkYhTgIakoSfBX11/EnR+5jOODo1z3j0/wtV89r75xEcmYAjxkb1u5kF99+vd490VN/MMju3nL3z3KHY/vUbeKiJyVAnweqKso5hsfWMvPPnUlq5qq+cqG51j/td9w7zMdurOPiJyRpS/lPTfWrVvn7e3tc/Z5UfXbXd189Zc72Xagl+WNFdz0pjZuuLSVSl1PRaQgmdlGd1/3quUK8PlpfNz5xbZObn/sJbZ2nKCyJMEfXtrCh9/YxoqFlWGXJyJzSAEeYZv393D37/by862djKbGedPyBVy3poV3XbiYmrKisMsTkRxTgOeB7r4RfvTUy/zrxg5ePjZIcTzGWy5o5L2XNPP7r1tIebG6WETykQI8j7g7WzpO8H+2HGTD1oMc7h2htCjGlcsbeNvKhbxt5UJaasvCLlNEskQBnqdS487Te4/xwLOdPPx8F/uPpW/htnJxFW+9YCFvXL6A159bpwOgIhGmAC8A7s6L3f08srObh3d28fTeYyTHnXjMWN1czeVt9Vy2tJ5Lz6mjsaok7HJFJEMK8AI0MJJk08s9PLXnKE/uOcam/T2TdwZqrinl4tZaLllSyyWtNaxuqdEBUZF56kwBfta/q83s+8B7gC53vzBY9iXg40B3sNl/dfdfZK9cyYaKkgRXndfAVec1ADCSTLG14wRb9vewpeMEWzt6+OX2Q5PbN9eUsrKpmpWLqyaf2xZUUJzQ+V4i81EmHaN3Af8A/NMpy29z969lvSLJmZJEnMva6rmsrX5y2fGBUbYeOMGOzl52dPays7OPx17oJhmcARqPGefWl7NiYeXkY2lDBUsbKqgtLw6rKSJCZnelf8zM2uagFglBXUUxbzm/kbec3zi5bCSZYndXP7sO97O7K/3Y1dXHwzu7JoMdoK68iKUNFbQ1VNC2oIJzF5TTtiA9XVOu7hiRXJvN0IRPmdl/ANqBz7j78dNtZGY3AzcDnHPOObP4OJkrJYk4q5trWN1cc9Ly0eQ4Lx8bZO+RAfYcGeClIwPsPTLA73Yf5d5nDpy0bV15EW0NFSxdUDEZ8ksbKljeWElZcXwumyOStzI6iBnsgW+Y0ge+CDgCOPAVoMnd/+xs76ODmPlreCw1Ge77jg6y5+jAZNB3nhie3M4MWuvKOG9hFecFXTLnL6rivEWVOhFJ5AxmfBDzdNz98JQ3/i6wYRa1SR4oLYpz/qIqzl9U9ap1g6NJ9h0d5KXugcnumN1d/Ty+6wijqfSoGDM4p76c8xdVcUEQ6MsaKlnaWKEx7CJnMKN/GWbW5O6dwez1wLbslST5prw4weuaqnldU/VJy5OpdJfMC4f7eeFwH88f6uP5w+m+9qmX0V1UXcKyhkraGiporSujpbaM5toyWurKWFRVQiKuUTJSmDIZRvhD4K1Ag5l1AF8E3mpma0h3oewF/mPuSpR8lYjHWNZYybLGSq6+cPHk8pFkKthj7+fF7gFe7O7npe4BfrX9EMcGRk96j5jBgsoSFlZNPEpprCqhrqKY2rIi6iqKqC0vpq48PV9dVkQ8ZnPdVJGcyGQUygdPs/iOHNQiAqQPor5Wd8zBniEO9Axz4PgQnSeG6OodoatvmK6+EbYd7OVo/wivdR+MqtIENWVF1JYXUVP2yqN66nTpK/PVpQmqg2UaEy/ziToXJVLKixOsWFjFioWvDvcJ4+NO7/AYxwfH6BkcpWdwjOODo5wYGqNncIwTQyc/Dvf2p6cHxyb75M+krChOdVliMuCrgx+DqT8CVaUJKkuKqCiJnzwdPKvLR7JFAS55JxYzasuLgxONKjJ+nbszPDZO7/AYvUNj9A6nA753KMmJoTH6hsfoHU6etK67f4Td3f2cGByjbyRJJlemKC2KTYZ6eXGCiuI45SUJyoviVJQkJpdXTqw/9bk4QXlJnPLiV16vH4XCpAAXCZgZZcVxyorjLKounfbrx8edvpEkAyNJ+keS9A1PPI8Fy1L0DycZGE2vGxpNMjCaYnA0/aNw6MQQAyMpBkaTDI6kzvrXwFTFiRjlxXHKitKPkqI4ZUUxyorjVBQnqCxJBD8O6R+GiS6hqindQ/UVxdRXFOsYQYQowEWyJBazya6UbBhNjjM4mv4RGBpNpcN+5JXQHxxNMTB13WiS4bEUQ2PjDI+lGB5LMTia4mj/IP3BD8vAWX4Y4jFjQUUxjcFB4Za6MlY0VnLeoipWLKxkYVUJZgr4+UIBLjJPFSdiFCeKs37NmZFk+i+BU7uDjg2M0tU7QnffKweF2/cdp284OfnaqtIEyxvTJ2Atb6xkeWMFyxdWck59OUXqxplzCnCRAlOSiFNSGWdB5dmvCe/udPeNBCdgvXJtnMde6OaejR2T28UMGipLWFRdyqLqEhZWl9JYWTI50mfyoG9Zug+/rDjdh1+aiBNTl82MKcBF5IzMjIXVpSysLuVNKxpOWtc7PMZL3QO82NXPvqMDHO4d4XDfMAd6htn0cg9HTxmzfyZlRXFKi2KUFsUpLYpTkohRMvGciFEcjwV/jaSni6Yui8coisdIxI1EzIjHgud4jOK4kYhNbG8UxWPEY1OfjXgsRiJmU14fO+l9YrFX3jceM2IWTJvNix8eBbiIzEh1aRFrltSyZkntadcnU+Ov6qbpHUofxJ3onx8aTTE0ln4eSaYYnui/T44zMpaifyTJaHI8/Uiln8dSr8yPpfyks3bn2tSwT8Rjrwr7RPyVsP/rGy466VLOWfn8rL6biEggEY9NjmzJpfFxJzmeDvKx8XFSqfRzMuWMpcaDhzOaHJ/cLplKTyeD7VJT3yM1zrin56e+d2rcSbmTSqWfp66b+tqTtg2mx90pz8FVOBXgIhJpsZhRHHRnlFFYlyrWYWMRkYhSgIuIRJQCXEQkohTgIiIRpQAXEYkoBbiISEQpwEVEIkoBLiISUeaZXIE+Wx9m1g3sm+HLG4AjWSwnbPnUnnxqC6g981k+tQUyb8+57t546sI5DfDZMLN2d18Xdh3Zkk/tyae2gNozn+VTW2D27VEXiohIRCnARUQiKkoBfnvYBWRZPrUnn9oCas98lk9tgVm2JzJ94CIicrIo7YGLiMgUCnARkYiKRICb2dVm9ryZ7TazL4Rdz3SZ2ffNrMvMtk1ZVm9mD5rZruC5LswaM2VmS8zsETN7zsy2m9ktwfLItcfMSs3sKTPbErTly8HypWb2ZPB9+7GZ5faWMllmZnEz22RmG4L5yLbHzPaa2bNmttnM2oNlkfuuAZhZrZndY2Y7zWyHmb1xtm2Z9wFuZnHgH4E/AFYBHzSzVeFWNW13AVefsuwLwEPufh7wUDAfBUngM+6+CrgC+GTw/yOK7RkB1rv7JcAa4GozuwL4KnCbu68AjgMfDa/EGbkF2DFlPurteZu7r5kyXjqK3zWAbwK/dPeVwCWk/x/Nri3uPq8fwBuBX02ZvxW4Ney6ZtCONmDblPnngaZgugl4PuwaZ9iu+4F3RL09QDnwDPAG0mfGJYLlJ33/5vsDaA2CYD2wAbCIt2cv0HDKssh914AaYA/BwJFstWXe74EDLcD+KfMdwbKoW+TuncH0IWBRmMXMhJm1AWuBJ4loe4Luhs1AF/Ag8CLQ4+7JYJOofd++AXwOGA/mFxDt9jjwf81so5ndHCyL4ndtKdAN3Bl0b33PzCqYZVuiEOB5z9M/v5Eaz2lmlcBPgU+7e+/UdVFqj7un3H0N6T3Xy4GV4VY0c2b2HqDL3TeGXUsWXeXul5LuQv2kmf3e1JUR+q4lgEuBb7v7WmCAU7pLZtKWKAT4AWDJlPnWYFnUHTazJoDguSvkejJmZkWkw/sH7n5vsDiy7QFw9x7gEdJdDLVmlghWRen7diXwPjPbC/yIdDfKN4lue3D3A8FzF3Af6R/ZKH7XOoAOd38ymL+HdKDPqi1RCPCngfOCI+nFwAeAn4VcUzb8DLgpmL6JdF/yvGdmBtwB7HD3r09ZFbn2mFmjmdUG02Wk+/J3kA7y9webRaItAO5+q7u3unsb6X8nD7v7h4hoe8yswsyqJqaBdwLbiOB3zd0PAfvN7IJg0duB55htW8Lu3M/wAMA1wAuk+yf/W9j1zKD+HwKdwBjpX+KPku6bfAjYBfwaqA+7zgzbchXpP/O2ApuDxzVRbA9wMbApaMs24H8Ey5cBTwG7gX8FSsKudQZteyuwIcrtCereEjy2T/zbj+J3Lah7DdAefN/+DaibbVt0Kr2ISERFoQtFREROQwEuIhJRCnARkYhSgIuIRJQCXEQkohTgIiIRpQAXEYmo/w/gJCDZuqeMRAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(list(loss_dict.keys()), list(loss_dict.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'crop_prediction_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('input.weight',\n",
       "              tensor([[ 1.4240e-01,  3.0208e-01,  3.3952e-01,  4.0957e-01, -2.1840e-01,\n",
       "                        7.7345e-02, -1.1007e-01, -6.7018e-02],\n",
       "                      [-1.6411e-01, -3.2685e-01, -3.2188e-02, -1.7808e-01,  2.6823e-01,\n",
       "                       -2.3882e-01,  1.7069e-01,  2.4261e-01],\n",
       "                      [-2.9862e-01,  1.3380e-01,  3.0032e-01,  8.4978e-02, -1.1280e-01,\n",
       "                        3.9817e-01,  3.1366e-01, -8.1339e-02],\n",
       "                      [-3.3819e-01, -7.2151e-02,  2.0203e-01, -3.1742e-01,  1.6309e-01,\n",
       "                       -3.4058e-01,  2.2519e-01,  2.2271e-01],\n",
       "                      [-1.3653e-01,  3.2881e-01, -2.8039e-01, -7.7726e-02, -1.7620e-01,\n",
       "                        7.9638e-02,  2.9207e-01, -2.4837e-01],\n",
       "                      [-2.6533e-01, -2.8714e-01,  2.9645e-02,  2.8596e-01,  2.1628e-01,\n",
       "                        2.1521e-01,  2.7535e-01, -3.3423e-01],\n",
       "                      [ 2.9354e-01, -1.7299e-01, -2.2842e-01,  1.5060e-01, -2.1313e-01,\n",
       "                       -1.2420e-01,  2.3784e-01,  1.7455e-02],\n",
       "                      [ 2.6589e-03, -2.3575e-01, -2.9266e-01,  1.5451e-01, -2.9297e-01,\n",
       "                        9.6555e-03,  4.6425e-02,  1.2983e-01],\n",
       "                      [ 7.8113e-02, -3.5014e-01,  2.0354e-01,  8.9727e-02,  3.4550e-01,\n",
       "                        5.4940e-02, -3.2907e-01,  3.1784e-02],\n",
       "                      [ 8.5027e-02,  3.2266e-01, -2.1427e-01, -1.4585e-01, -1.3510e-01,\n",
       "                        2.3001e-01,  4.6539e-02, -2.3621e-01],\n",
       "                      [ 2.4505e-01,  1.2278e-01, -2.4933e-01,  3.8219e-01,  4.5098e-01,\n",
       "                       -5.6703e-02, -2.0738e-02, -2.7720e-01],\n",
       "                      [ 2.8449e-01, -3.4173e-01,  1.7214e-01,  2.4358e-01, -3.7912e-01,\n",
       "                       -5.6290e-02, -1.8460e-01,  1.6423e-01],\n",
       "                      [-8.0803e-02,  2.2736e-01, -3.2282e-01,  3.0734e-01, -8.4570e-02,\n",
       "                        2.3535e-01, -2.9111e-01,  2.4128e-02],\n",
       "                      [-3.5145e-01,  2.9469e-01, -1.0473e-02, -1.2858e-01, -1.7325e-01,\n",
       "                        2.3049e-01,  3.1718e-01, -6.4269e-02],\n",
       "                      [ 3.1155e-01,  1.8785e-01, -2.7525e-01, -3.2683e-01,  1.3108e-01,\n",
       "                       -4.5039e-02,  7.1295e-02,  1.0590e-01],\n",
       "                      [-1.4149e-02, -5.6659e-02,  2.2329e-01, -5.4066e-02, -1.3932e-01,\n",
       "                        1.6134e-01, -1.8559e-01, -2.7663e-01],\n",
       "                      [ 1.2911e-01,  5.1494e-02,  8.2068e-02, -1.2603e-01, -6.4939e-02,\n",
       "                        2.7277e-01,  4.2378e-02, -1.8285e-01],\n",
       "                      [-3.1099e-01,  1.3142e-01,  2.0098e-01, -1.3360e-01,  2.3552e-02,\n",
       "                       -3.0665e-01,  4.4835e-02,  3.0397e-01],\n",
       "                      [ 2.8312e-01, -3.4624e-01,  4.7223e-02, -3.3249e-01, -2.3504e-01,\n",
       "                        2.7385e-01,  3.2831e-01,  2.2339e-01],\n",
       "                      [-1.9647e-01, -3.1262e-01,  3.7448e-01, -2.3283e-01,  2.9190e-01,\n",
       "                        3.9999e-01,  1.4839e-01,  2.5432e-02],\n",
       "                      [ 3.2453e-01, -1.7407e-01, -2.4976e-01,  1.9212e-01,  3.1824e-01,\n",
       "                        2.0594e-01, -1.4348e-01,  3.0517e-01],\n",
       "                      [ 1.7710e-01, -2.3167e-01, -6.3289e-02,  2.4409e-01,  2.6072e-02,\n",
       "                        3.2994e-01, -2.2519e-01,  3.3582e-01],\n",
       "                      [ 2.0413e-01,  4.8716e-02,  1.2877e-01,  1.7005e-01, -1.1270e-01,\n",
       "                       -3.4320e-01,  9.2843e-02,  2.6733e-01],\n",
       "                      [ 1.3660e-01, -8.6473e-02,  1.3970e-01, -1.1355e-01, -1.2986e-01,\n",
       "                       -2.2345e-01,  2.1543e-01, -2.2261e-01],\n",
       "                      [-1.3919e-01, -1.2147e-01,  3.6175e-01, -7.0732e-03,  3.3509e-01,\n",
       "                        1.5589e-01,  2.1116e-02, -1.4959e-01],\n",
       "                      [ 2.8718e-01, -1.2129e-01,  2.2707e-01,  2.3529e-02,  3.3529e-01,\n",
       "                       -3.6892e-01, -2.8835e-01, -5.6738e-03],\n",
       "                      [-1.0630e-01,  3.3397e-01, -3.0560e-01,  3.3230e-01,  2.5918e-01,\n",
       "                        1.7609e-01,  3.5533e-01,  1.3317e-01],\n",
       "                      [-5.3544e-02,  1.8228e-01,  1.7682e-01,  3.3052e-01,  6.7296e-02,\n",
       "                        2.0060e-01, -4.6851e-01, -3.7490e-01],\n",
       "                      [ 7.3580e-02, -1.5881e-01,  3.7242e-01,  3.9363e-01, -3.1687e-01,\n",
       "                       -1.8624e-01,  2.7052e-01, -2.8958e-01],\n",
       "                      [ 2.1871e-01,  2.6717e-01,  1.0754e-01,  2.2469e-01, -7.2467e-02,\n",
       "                       -5.8409e-02,  2.6826e-01,  2.8667e-01],\n",
       "                      [-2.4402e-01, -2.9252e-01, -6.8823e-02,  1.5803e-01,  3.6501e-01,\n",
       "                        1.6458e-01,  3.8882e-01, -6.6492e-02],\n",
       "                      [-1.3059e-02,  3.1041e-02, -2.3342e-01, -2.2651e-01,  1.9279e-01,\n",
       "                        2.1095e-01, -8.1233e-02,  1.1332e-01],\n",
       "                      [ 3.0436e-01,  1.1376e-01, -3.1887e-01, -3.5339e-01,  2.1493e-01,\n",
       "                       -1.2574e-01, -2.7642e-01,  2.3652e-01],\n",
       "                      [-2.4928e-01,  1.7518e-01,  1.2429e-01,  2.1034e-01, -1.9285e-01,\n",
       "                        2.2077e-01, -3.2459e-01,  3.2868e-01],\n",
       "                      [-3.2679e-01, -1.7558e-01,  6.1477e-02, -2.2173e-01,  1.3136e-01,\n",
       "                        2.5048e-01, -3.0098e-01, -6.5929e-02],\n",
       "                      [-2.6523e-01,  9.6640e-02, -3.3599e-01, -1.4578e-01,  4.5193e-02,\n",
       "                        1.8626e-01, -3.4052e-01, -3.3796e-01],\n",
       "                      [ 1.6688e-01,  3.1369e-01, -2.7203e-01, -3.3376e-01, -1.1129e-02,\n",
       "                        2.7787e-01, -1.7464e-01,  2.5820e-01],\n",
       "                      [-2.9010e-01,  1.8629e-01,  2.5278e-01,  2.3111e-01, -2.6883e-01,\n",
       "                       -1.4575e-01, -1.9943e-01, -3.1558e-01],\n",
       "                      [-2.7100e-01, -4.9177e-02,  1.0142e-01,  5.4107e-02,  4.5620e-02,\n",
       "                        1.5108e-01,  1.6490e-01,  7.9315e-02],\n",
       "                      [ 2.2190e-01, -3.2768e-02,  2.3176e-02,  1.8896e-01, -3.8715e-01,\n",
       "                        5.4354e-02,  3.5764e-01, -1.5883e-01],\n",
       "                      [ 1.8485e-01,  2.4250e-01,  1.4479e-01, -5.2998e-02,  3.4914e-03,\n",
       "                       -1.2099e-01, -1.3709e-01, -4.2240e-01],\n",
       "                      [ 3.8283e-02,  2.6796e-01,  6.2880e-02,  3.7564e-02,  8.6948e-03,\n",
       "                       -2.7683e-01,  1.4914e-02,  2.3113e-01],\n",
       "                      [ 7.1803e-02,  1.7245e-01, -6.5713e-02,  2.0823e-01,  1.5971e-02,\n",
       "                       -2.5547e-01, -1.3505e-01, -1.9164e-01],\n",
       "                      [ 2.5191e-01, -2.7316e-02,  3.0647e-01,  1.2887e-01, -3.8865e-01,\n",
       "                       -9.8361e-02, -3.9169e-03, -2.8961e-02],\n",
       "                      [-2.5474e-01, -1.2103e-02,  6.3302e-02, -3.4051e-01, -2.2493e-01,\n",
       "                       -2.8006e-01, -2.7011e-01,  1.7227e-01],\n",
       "                      [-1.8457e-01,  1.5206e-01, -1.2869e-01,  2.0489e-02, -2.6576e-01,\n",
       "                        9.1884e-02, -2.3830e-01, -2.9322e-01],\n",
       "                      [-2.0632e-01, -1.8689e-01,  2.6278e-01, -3.2214e-01,  8.6991e-02,\n",
       "                       -3.7381e-01,  3.2853e-01, -4.7730e-02],\n",
       "                      [ 2.7897e-01,  2.3755e-01, -1.7298e-03, -3.5956e-02, -4.0767e-01,\n",
       "                        2.3393e-01,  1.7414e-01,  3.2188e-01],\n",
       "                      [-9.0364e-02, -2.4558e-01,  3.5426e-02,  1.9119e-01,  2.8196e-01,\n",
       "                       -3.8903e-01,  3.1892e-01, -1.1739e-01],\n",
       "                      [ 1.9904e-01, -3.0322e-01, -2.3624e-01,  2.9491e-01,  4.4340e-02,\n",
       "                        1.3812e-01, -3.0831e-02,  2.3630e-01],\n",
       "                      [-7.2031e-02, -3.2603e-01, -1.5851e-01,  2.6882e-01,  2.0769e-02,\n",
       "                       -6.8604e-02, -8.8316e-02,  8.9982e-04],\n",
       "                      [ 1.8432e-01,  1.0798e-01, -9.4132e-02,  1.6111e-01,  1.5177e-01,\n",
       "                        3.7928e-01, -1.2328e-01, -3.9921e-01],\n",
       "                      [ 1.7192e-01, -1.1539e-01, -3.0341e-01,  2.0377e-01,  1.8632e-01,\n",
       "                        1.7588e-02, -3.2047e-01,  1.2105e-01],\n",
       "                      [-2.3737e-01,  1.7700e-01,  1.0430e-01,  2.0157e-01, -2.4299e-01,\n",
       "                       -2.1813e-01,  2.6657e-01,  1.6509e-01],\n",
       "                      [-1.3859e-01,  2.1819e-01,  3.1393e-01,  2.7897e-02, -2.3338e-01,\n",
       "                       -2.5321e-01, -2.2650e-02, -3.3400e-01],\n",
       "                      [ 3.0648e-01, -3.0164e-01, -6.2389e-02,  1.3987e-01, -2.8120e-01,\n",
       "                        4.0974e-01,  3.0965e-01,  3.3536e-01],\n",
       "                      [-2.1000e-01,  3.2076e-01,  2.3667e-01,  2.1717e-02, -3.6301e-02,\n",
       "                       -2.6302e-01,  3.4149e-01, -1.7640e-01],\n",
       "                      [ 3.2111e-02, -2.4993e-01, -4.9189e-02,  3.3237e-01,  7.8668e-02,\n",
       "                       -2.6746e-01, -4.0974e-02,  9.1779e-02],\n",
       "                      [ 1.5217e-01, -3.3670e-01, -8.4497e-02,  3.4645e-01, -2.1971e-01,\n",
       "                       -2.2276e-01,  2.2474e-01,  2.9539e-01],\n",
       "                      [-3.7468e-02,  1.2798e-01,  1.0940e-01, -6.8459e-02, -2.7274e-01,\n",
       "                       -2.6102e-01, -2.9084e-01,  1.2440e-01],\n",
       "                      [ 2.7379e-01, -1.1980e-01,  2.4839e-01, -3.0727e-01,  4.5219e-01,\n",
       "                        1.6663e-01, -7.2373e-02,  6.9790e-02],\n",
       "                      [-2.7292e-01, -9.2614e-02,  2.4592e-01, -1.2056e-01,  1.3145e-01,\n",
       "                       -8.8693e-02, -2.7771e-01, -3.0931e-01],\n",
       "                      [-1.9597e-01,  1.5920e-01,  8.4127e-02,  3.0504e-01,  1.7131e-01,\n",
       "                       -2.2892e-01,  3.5955e-01, -3.1694e-01],\n",
       "                      [ 1.8318e-01,  2.6741e-01, -8.1156e-02,  4.0497e-04,  1.2991e-01,\n",
       "                       -7.3469e-02, -3.2383e-02,  3.9939e-01]])),\n",
       "             ('input.bias',\n",
       "              tensor([ 0.2941, -0.0799,  0.1280, -0.1956, -0.1107,  0.3220,  0.1479,  0.1670,\n",
       "                      -0.2371, -0.2083, -0.1401,  0.0170,  0.1307,  0.1765,  0.1371, -0.3100,\n",
       "                      -0.0076, -0.2627,  0.3165,  0.1773,  0.0164,  0.0106,  0.1997, -0.1731,\n",
       "                       0.0285,  0.2929,  0.0253, -0.3077, -0.1535,  0.0208, -0.2103, -0.0501,\n",
       "                      -0.0378, -0.2279, -0.0216,  0.3034, -0.3316,  0.1552, -0.0743,  0.1736,\n",
       "                       0.0817, -0.2727,  0.2772, -0.3124,  0.2021, -0.3382, -0.2015,  0.2622,\n",
       "                      -0.0081,  0.0797,  0.1528,  0.2474, -0.2514, -0.1594,  0.2204, -0.2160,\n",
       "                       0.1267, -0.2843, -0.1900,  0.0559, -0.3175, -0.1287,  0.3001,  0.2452])),\n",
       "             ('hidden1.weight',\n",
       "              tensor([[ 0.1317,  0.1041,  0.0507,  ...,  0.0642,  0.1762, -0.0729],\n",
       "                      [ 0.0115,  0.1022, -0.0746,  ..., -0.0462, -0.0398, -0.0670],\n",
       "                      [ 0.0086,  0.0023, -0.0725,  ..., -0.0598, -0.0778,  0.1119],\n",
       "                      ...,\n",
       "                      [ 0.0718, -0.0836, -0.0881,  ...,  0.1239, -0.0205, -0.0419],\n",
       "                      [ 0.0353, -0.0869, -0.1308,  ..., -0.0697,  0.0790, -0.0519],\n",
       "                      [-0.1535,  0.0661, -0.1263,  ...,  0.1270,  0.0762, -0.0231]])),\n",
       "             ('hidden1.bias',\n",
       "              tensor([-0.0837,  0.0528,  0.0471, -0.0330, -0.0937,  0.0228,  0.0784,  0.0476,\n",
       "                       0.0753, -0.0720,  0.1030, -0.1250, -0.0274,  0.0541,  0.0077,  0.1243,\n",
       "                       0.1107,  0.1078, -0.0186,  0.0836,  0.0611,  0.1095,  0.0335, -0.1057,\n",
       "                      -0.0592,  0.1089, -0.1088,  0.0305,  0.1072,  0.0276,  0.0150, -0.0728,\n",
       "                       0.1230,  0.1081, -0.0007, -0.0325, -0.0560, -0.0682,  0.1041, -0.1077,\n",
       "                      -0.0477,  0.0168, -0.1245,  0.0220, -0.1180,  0.1093,  0.0417, -0.0987,\n",
       "                      -0.0869, -0.1038, -0.0975, -0.1265, -0.0021,  0.0685,  0.0409,  0.0333,\n",
       "                       0.0489, -0.0657, -0.0154,  0.0537, -0.1195, -0.1181, -0.0955, -0.1165])),\n",
       "             ('hidden2.weight',\n",
       "              tensor([[-0.0340,  0.1065,  0.0687,  ...,  0.0448,  0.1381, -0.0038],\n",
       "                      [ 0.1607,  0.1102,  0.1083,  ...,  0.0186, -0.0368,  0.0495],\n",
       "                      [-0.0215, -0.0338, -0.1230,  ...,  0.1032, -0.1062, -0.0847],\n",
       "                      ...,\n",
       "                      [-0.1179,  0.0893, -0.0299,  ..., -0.0110,  0.0177, -0.0288],\n",
       "                      [ 0.2045,  0.0459,  0.0515,  ...,  0.0153,  0.1197, -0.0975],\n",
       "                      [-0.0330, -0.1127,  0.0100,  ..., -0.0373,  0.0511,  0.0419]])),\n",
       "             ('hidden2.bias',\n",
       "              tensor([-0.0032, -0.0048, -0.0440,  0.0457, -0.1178, -0.0296,  0.0782,  0.0486,\n",
       "                      -0.0228,  0.0174,  0.1298,  0.1050,  0.0650,  0.1036,  0.0774, -0.0513,\n",
       "                      -0.0483, -0.0956,  0.1031, -0.0412,  0.0947,  0.0521, -0.0196,  0.0360,\n",
       "                       0.0811,  0.0158,  0.0629,  0.0983, -0.0589]))])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('input.weight',\n",
       "              tensor([[ 1.4240e-01,  3.0208e-01,  3.3952e-01,  4.0957e-01, -2.1840e-01,\n",
       "                        7.7345e-02, -1.1007e-01, -6.7018e-02],\n",
       "                      [-1.6411e-01, -3.2685e-01, -3.2188e-02, -1.7808e-01,  2.6823e-01,\n",
       "                       -2.3882e-01,  1.7069e-01,  2.4261e-01],\n",
       "                      [-2.9862e-01,  1.3380e-01,  3.0032e-01,  8.4978e-02, -1.1280e-01,\n",
       "                        3.9817e-01,  3.1366e-01, -8.1339e-02],\n",
       "                      [-3.3819e-01, -7.2151e-02,  2.0203e-01, -3.1742e-01,  1.6309e-01,\n",
       "                       -3.4058e-01,  2.2519e-01,  2.2271e-01],\n",
       "                      [-1.3653e-01,  3.2881e-01, -2.8039e-01, -7.7726e-02, -1.7620e-01,\n",
       "                        7.9638e-02,  2.9207e-01, -2.4837e-01],\n",
       "                      [-2.6533e-01, -2.8714e-01,  2.9645e-02,  2.8596e-01,  2.1628e-01,\n",
       "                        2.1521e-01,  2.7535e-01, -3.3423e-01],\n",
       "                      [ 2.9354e-01, -1.7299e-01, -2.2842e-01,  1.5060e-01, -2.1313e-01,\n",
       "                       -1.2420e-01,  2.3784e-01,  1.7455e-02],\n",
       "                      [ 2.6589e-03, -2.3575e-01, -2.9266e-01,  1.5451e-01, -2.9297e-01,\n",
       "                        9.6555e-03,  4.6425e-02,  1.2983e-01],\n",
       "                      [ 7.8113e-02, -3.5014e-01,  2.0354e-01,  8.9727e-02,  3.4550e-01,\n",
       "                        5.4940e-02, -3.2907e-01,  3.1784e-02],\n",
       "                      [ 8.5027e-02,  3.2266e-01, -2.1427e-01, -1.4585e-01, -1.3510e-01,\n",
       "                        2.3001e-01,  4.6539e-02, -2.3621e-01],\n",
       "                      [ 2.4505e-01,  1.2278e-01, -2.4933e-01,  3.8219e-01,  4.5098e-01,\n",
       "                       -5.6703e-02, -2.0738e-02, -2.7720e-01],\n",
       "                      [ 2.8449e-01, -3.4173e-01,  1.7214e-01,  2.4358e-01, -3.7912e-01,\n",
       "                       -5.6290e-02, -1.8460e-01,  1.6423e-01],\n",
       "                      [-8.0803e-02,  2.2736e-01, -3.2282e-01,  3.0734e-01, -8.4570e-02,\n",
       "                        2.3535e-01, -2.9111e-01,  2.4128e-02],\n",
       "                      [-3.5145e-01,  2.9469e-01, -1.0473e-02, -1.2858e-01, -1.7325e-01,\n",
       "                        2.3049e-01,  3.1718e-01, -6.4269e-02],\n",
       "                      [ 3.1155e-01,  1.8785e-01, -2.7525e-01, -3.2683e-01,  1.3108e-01,\n",
       "                       -4.5039e-02,  7.1295e-02,  1.0590e-01],\n",
       "                      [-1.4149e-02, -5.6659e-02,  2.2329e-01, -5.4066e-02, -1.3932e-01,\n",
       "                        1.6134e-01, -1.8559e-01, -2.7663e-01],\n",
       "                      [ 1.2911e-01,  5.1494e-02,  8.2068e-02, -1.2603e-01, -6.4939e-02,\n",
       "                        2.7277e-01,  4.2378e-02, -1.8285e-01],\n",
       "                      [-3.1099e-01,  1.3142e-01,  2.0098e-01, -1.3360e-01,  2.3552e-02,\n",
       "                       -3.0665e-01,  4.4835e-02,  3.0397e-01],\n",
       "                      [ 2.8312e-01, -3.4624e-01,  4.7223e-02, -3.3249e-01, -2.3504e-01,\n",
       "                        2.7385e-01,  3.2831e-01,  2.2339e-01],\n",
       "                      [-1.9647e-01, -3.1262e-01,  3.7448e-01, -2.3283e-01,  2.9190e-01,\n",
       "                        3.9999e-01,  1.4839e-01,  2.5432e-02],\n",
       "                      [ 3.2453e-01, -1.7407e-01, -2.4976e-01,  1.9212e-01,  3.1824e-01,\n",
       "                        2.0594e-01, -1.4348e-01,  3.0517e-01],\n",
       "                      [ 1.7710e-01, -2.3167e-01, -6.3289e-02,  2.4409e-01,  2.6072e-02,\n",
       "                        3.2994e-01, -2.2519e-01,  3.3582e-01],\n",
       "                      [ 2.0413e-01,  4.8716e-02,  1.2877e-01,  1.7005e-01, -1.1270e-01,\n",
       "                       -3.4320e-01,  9.2843e-02,  2.6733e-01],\n",
       "                      [ 1.3660e-01, -8.6473e-02,  1.3970e-01, -1.1355e-01, -1.2986e-01,\n",
       "                       -2.2345e-01,  2.1543e-01, -2.2261e-01],\n",
       "                      [-1.3919e-01, -1.2147e-01,  3.6175e-01, -7.0732e-03,  3.3509e-01,\n",
       "                        1.5589e-01,  2.1116e-02, -1.4959e-01],\n",
       "                      [ 2.8718e-01, -1.2129e-01,  2.2707e-01,  2.3529e-02,  3.3529e-01,\n",
       "                       -3.6892e-01, -2.8835e-01, -5.6738e-03],\n",
       "                      [-1.0630e-01,  3.3397e-01, -3.0560e-01,  3.3230e-01,  2.5918e-01,\n",
       "                        1.7609e-01,  3.5533e-01,  1.3317e-01],\n",
       "                      [-5.3544e-02,  1.8228e-01,  1.7682e-01,  3.3052e-01,  6.7296e-02,\n",
       "                        2.0060e-01, -4.6851e-01, -3.7490e-01],\n",
       "                      [ 7.3580e-02, -1.5881e-01,  3.7242e-01,  3.9363e-01, -3.1687e-01,\n",
       "                       -1.8624e-01,  2.7052e-01, -2.8958e-01],\n",
       "                      [ 2.1871e-01,  2.6717e-01,  1.0754e-01,  2.2469e-01, -7.2467e-02,\n",
       "                       -5.8409e-02,  2.6826e-01,  2.8667e-01],\n",
       "                      [-2.4402e-01, -2.9252e-01, -6.8823e-02,  1.5803e-01,  3.6501e-01,\n",
       "                        1.6458e-01,  3.8882e-01, -6.6492e-02],\n",
       "                      [-1.3059e-02,  3.1041e-02, -2.3342e-01, -2.2651e-01,  1.9279e-01,\n",
       "                        2.1095e-01, -8.1233e-02,  1.1332e-01],\n",
       "                      [ 3.0436e-01,  1.1376e-01, -3.1887e-01, -3.5339e-01,  2.1493e-01,\n",
       "                       -1.2574e-01, -2.7642e-01,  2.3652e-01],\n",
       "                      [-2.4928e-01,  1.7518e-01,  1.2429e-01,  2.1034e-01, -1.9285e-01,\n",
       "                        2.2077e-01, -3.2459e-01,  3.2868e-01],\n",
       "                      [-3.2679e-01, -1.7558e-01,  6.1477e-02, -2.2173e-01,  1.3136e-01,\n",
       "                        2.5048e-01, -3.0098e-01, -6.5929e-02],\n",
       "                      [-2.6523e-01,  9.6640e-02, -3.3599e-01, -1.4578e-01,  4.5193e-02,\n",
       "                        1.8626e-01, -3.4052e-01, -3.3796e-01],\n",
       "                      [ 1.6688e-01,  3.1369e-01, -2.7203e-01, -3.3376e-01, -1.1129e-02,\n",
       "                        2.7787e-01, -1.7464e-01,  2.5820e-01],\n",
       "                      [-2.9010e-01,  1.8629e-01,  2.5278e-01,  2.3111e-01, -2.6883e-01,\n",
       "                       -1.4575e-01, -1.9943e-01, -3.1558e-01],\n",
       "                      [-2.7100e-01, -4.9177e-02,  1.0142e-01,  5.4107e-02,  4.5620e-02,\n",
       "                        1.5108e-01,  1.6490e-01,  7.9315e-02],\n",
       "                      [ 2.2190e-01, -3.2768e-02,  2.3176e-02,  1.8896e-01, -3.8715e-01,\n",
       "                        5.4354e-02,  3.5764e-01, -1.5883e-01],\n",
       "                      [ 1.8485e-01,  2.4250e-01,  1.4479e-01, -5.2998e-02,  3.4914e-03,\n",
       "                       -1.2099e-01, -1.3709e-01, -4.2240e-01],\n",
       "                      [ 3.8283e-02,  2.6796e-01,  6.2880e-02,  3.7564e-02,  8.6948e-03,\n",
       "                       -2.7683e-01,  1.4914e-02,  2.3113e-01],\n",
       "                      [ 7.1803e-02,  1.7245e-01, -6.5713e-02,  2.0823e-01,  1.5971e-02,\n",
       "                       -2.5547e-01, -1.3505e-01, -1.9164e-01],\n",
       "                      [ 2.5191e-01, -2.7316e-02,  3.0647e-01,  1.2887e-01, -3.8865e-01,\n",
       "                       -9.8361e-02, -3.9169e-03, -2.8961e-02],\n",
       "                      [-2.5474e-01, -1.2103e-02,  6.3302e-02, -3.4051e-01, -2.2493e-01,\n",
       "                       -2.8006e-01, -2.7011e-01,  1.7227e-01],\n",
       "                      [-1.8457e-01,  1.5206e-01, -1.2869e-01,  2.0489e-02, -2.6576e-01,\n",
       "                        9.1884e-02, -2.3830e-01, -2.9322e-01],\n",
       "                      [-2.0632e-01, -1.8689e-01,  2.6278e-01, -3.2214e-01,  8.6991e-02,\n",
       "                       -3.7381e-01,  3.2853e-01, -4.7730e-02],\n",
       "                      [ 2.7897e-01,  2.3755e-01, -1.7298e-03, -3.5956e-02, -4.0767e-01,\n",
       "                        2.3393e-01,  1.7414e-01,  3.2188e-01],\n",
       "                      [-9.0364e-02, -2.4558e-01,  3.5426e-02,  1.9119e-01,  2.8196e-01,\n",
       "                       -3.8903e-01,  3.1892e-01, -1.1739e-01],\n",
       "                      [ 1.9904e-01, -3.0322e-01, -2.3624e-01,  2.9491e-01,  4.4340e-02,\n",
       "                        1.3812e-01, -3.0831e-02,  2.3630e-01],\n",
       "                      [-7.2031e-02, -3.2603e-01, -1.5851e-01,  2.6882e-01,  2.0769e-02,\n",
       "                       -6.8604e-02, -8.8316e-02,  8.9982e-04],\n",
       "                      [ 1.8432e-01,  1.0798e-01, -9.4132e-02,  1.6111e-01,  1.5177e-01,\n",
       "                        3.7928e-01, -1.2328e-01, -3.9921e-01],\n",
       "                      [ 1.7192e-01, -1.1539e-01, -3.0341e-01,  2.0377e-01,  1.8632e-01,\n",
       "                        1.7588e-02, -3.2047e-01,  1.2105e-01],\n",
       "                      [-2.3737e-01,  1.7700e-01,  1.0430e-01,  2.0157e-01, -2.4299e-01,\n",
       "                       -2.1813e-01,  2.6657e-01,  1.6509e-01],\n",
       "                      [-1.3859e-01,  2.1819e-01,  3.1393e-01,  2.7897e-02, -2.3338e-01,\n",
       "                       -2.5321e-01, -2.2650e-02, -3.3400e-01],\n",
       "                      [ 3.0648e-01, -3.0164e-01, -6.2389e-02,  1.3987e-01, -2.8120e-01,\n",
       "                        4.0974e-01,  3.0965e-01,  3.3536e-01],\n",
       "                      [-2.1000e-01,  3.2076e-01,  2.3667e-01,  2.1717e-02, -3.6301e-02,\n",
       "                       -2.6302e-01,  3.4149e-01, -1.7640e-01],\n",
       "                      [ 3.2111e-02, -2.4993e-01, -4.9189e-02,  3.3237e-01,  7.8668e-02,\n",
       "                       -2.6746e-01, -4.0974e-02,  9.1779e-02],\n",
       "                      [ 1.5217e-01, -3.3670e-01, -8.4497e-02,  3.4645e-01, -2.1971e-01,\n",
       "                       -2.2276e-01,  2.2474e-01,  2.9539e-01],\n",
       "                      [-3.7468e-02,  1.2798e-01,  1.0940e-01, -6.8459e-02, -2.7274e-01,\n",
       "                       -2.6102e-01, -2.9084e-01,  1.2440e-01],\n",
       "                      [ 2.7379e-01, -1.1980e-01,  2.4839e-01, -3.0727e-01,  4.5219e-01,\n",
       "                        1.6663e-01, -7.2373e-02,  6.9790e-02],\n",
       "                      [-2.7292e-01, -9.2614e-02,  2.4592e-01, -1.2056e-01,  1.3145e-01,\n",
       "                       -8.8693e-02, -2.7771e-01, -3.0931e-01],\n",
       "                      [-1.9597e-01,  1.5920e-01,  8.4127e-02,  3.0504e-01,  1.7131e-01,\n",
       "                       -2.2892e-01,  3.5955e-01, -3.1694e-01],\n",
       "                      [ 1.8318e-01,  2.6741e-01, -8.1156e-02,  4.0497e-04,  1.2991e-01,\n",
       "                       -7.3469e-02, -3.2383e-02,  3.9939e-01]])),\n",
       "             ('input.bias',\n",
       "              tensor([ 0.2941, -0.0799,  0.1280, -0.1956, -0.1107,  0.3220,  0.1479,  0.1670,\n",
       "                      -0.2371, -0.2083, -0.1401,  0.0170,  0.1307,  0.1765,  0.1371, -0.3100,\n",
       "                      -0.0076, -0.2627,  0.3165,  0.1773,  0.0164,  0.0106,  0.1997, -0.1731,\n",
       "                       0.0285,  0.2929,  0.0253, -0.3077, -0.1535,  0.0208, -0.2103, -0.0501,\n",
       "                      -0.0378, -0.2279, -0.0216,  0.3034, -0.3316,  0.1552, -0.0743,  0.1736,\n",
       "                       0.0817, -0.2727,  0.2772, -0.3124,  0.2021, -0.3382, -0.2015,  0.2622,\n",
       "                      -0.0081,  0.0797,  0.1528,  0.2474, -0.2514, -0.1594,  0.2204, -0.2160,\n",
       "                       0.1267, -0.2843, -0.1900,  0.0559, -0.3175, -0.1287,  0.3001,  0.2452])),\n",
       "             ('hidden1.weight',\n",
       "              tensor([[ 0.1317,  0.1041,  0.0507,  ...,  0.0642,  0.1762, -0.0729],\n",
       "                      [ 0.0115,  0.1022, -0.0746,  ..., -0.0462, -0.0398, -0.0670],\n",
       "                      [ 0.0086,  0.0023, -0.0725,  ..., -0.0598, -0.0778,  0.1119],\n",
       "                      ...,\n",
       "                      [ 0.0718, -0.0836, -0.0881,  ...,  0.1239, -0.0205, -0.0419],\n",
       "                      [ 0.0353, -0.0869, -0.1308,  ..., -0.0697,  0.0790, -0.0519],\n",
       "                      [-0.1535,  0.0661, -0.1263,  ...,  0.1270,  0.0762, -0.0231]])),\n",
       "             ('hidden1.bias',\n",
       "              tensor([-0.0837,  0.0528,  0.0471, -0.0330, -0.0937,  0.0228,  0.0784,  0.0476,\n",
       "                       0.0753, -0.0720,  0.1030, -0.1250, -0.0274,  0.0541,  0.0077,  0.1243,\n",
       "                       0.1107,  0.1078, -0.0186,  0.0836,  0.0611,  0.1095,  0.0335, -0.1057,\n",
       "                      -0.0592,  0.1089, -0.1088,  0.0305,  0.1072,  0.0276,  0.0150, -0.0728,\n",
       "                       0.1230,  0.1081, -0.0007, -0.0325, -0.0560, -0.0682,  0.1041, -0.1077,\n",
       "                      -0.0477,  0.0168, -0.1245,  0.0220, -0.1180,  0.1093,  0.0417, -0.0987,\n",
       "                      -0.0869, -0.1038, -0.0975, -0.1265, -0.0021,  0.0685,  0.0409,  0.0333,\n",
       "                       0.0489, -0.0657, -0.0154,  0.0537, -0.1195, -0.1181, -0.0955, -0.1165])),\n",
       "             ('hidden2.weight',\n",
       "              tensor([[-0.0340,  0.1065,  0.0687,  ...,  0.0448,  0.1381, -0.0038],\n",
       "                      [ 0.1607,  0.1102,  0.1083,  ...,  0.0186, -0.0368,  0.0495],\n",
       "                      [-0.0215, -0.0338, -0.1230,  ...,  0.1032, -0.1062, -0.0847],\n",
       "                      ...,\n",
       "                      [-0.1179,  0.0893, -0.0299,  ..., -0.0110,  0.0177, -0.0288],\n",
       "                      [ 0.2045,  0.0459,  0.0515,  ...,  0.0153,  0.1197, -0.0975],\n",
       "                      [-0.0330, -0.1127,  0.0100,  ..., -0.0373,  0.0511,  0.0419]])),\n",
       "             ('hidden2.bias',\n",
       "              tensor([-0.0032, -0.0048, -0.0440,  0.0457, -0.1178, -0.0296,  0.0782,  0.0486,\n",
       "                      -0.0228,  0.0174,  0.1298,  0.1050,  0.0650,  0.1036,  0.0774, -0.0513,\n",
       "                      -0.0483, -0.0956,  0.1031, -0.0412,  0.0947,  0.0521, -0.0196,  0.0360,\n",
       "                       0.0811,  0.0158,  0.0629,  0.0983, -0.0589]))])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "model2 = Model()\n",
    "model2.load_state_dict(torch.load('crop_prediction_weights.pth'))\n",
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}