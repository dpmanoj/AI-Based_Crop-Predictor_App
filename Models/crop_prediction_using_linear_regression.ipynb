{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('pytor1.12': conda)",
   "display_name": "Python 3.6.10 64-bit ('pytor1.12': conda)",
   "metadata": {
    "interpreter": {
     "hash": "521b0883aadebb34975bad4f964c25c8a8224771a5b887cc0070c3c89f50aff7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv file\n",
    "df = pd.read_csv('../dataset/crops_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting from pandas dataframe to numpy\n",
    "np_inputs = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[33.259373   7.030931  60.84086   ... 15.602418   6.7222724 10.1207695]\n",
      " [33.324234   6.562556  64.75895   ... 16.013498   6.084758  11.4723835]\n",
      " [33.736282   6.557421  61.573425  ... 16.430769   5.703082  11.680659 ]\n",
      " ...\n",
      " [25.8816     6.181125  30.692217  ... 53.876553  23.047926  12.743419 ]\n",
      " [24.774702   6.929148  58.6065    ... 47.295223  24.395452  11.042995 ]\n",
      " [23.613468   6.6437187 53.63108   ... 54.34586   26.842375  13.102743 ]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# inputs are from col-6 to col-13\n",
    "inputs = np_inputs[:, 6:14]\n",
    "inputs = np.array(inputs, dtype='float32')\n",
    "\n",
    "print(inputs)\n",
    "\n",
    "\n",
    "# convert output crops to binary encoded labels\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(np_inputs[:,14])\n",
    "outputs = lb.transform(np_inputs[:,14])\n",
    "\n",
    "outputs = np.array(outputs, dtype='float32')\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[33.2594,  7.0309, 60.8409,  ..., 15.6024,  6.7223, 10.1208],\n        [33.3242,  6.5626, 64.7589,  ..., 16.0135,  6.0848, 11.4724],\n        [33.7363,  6.5574, 61.5734,  ..., 16.4308,  5.7031, 11.6807],\n        ...,\n        [25.8816,  6.1811, 30.6922,  ..., 53.8766, 23.0479, 12.7434],\n        [24.7747,  6.9291, 58.6065,  ..., 47.2952, 24.3955, 11.0430],\n        [23.6135,  6.6437, 53.6311,  ..., 54.3459, 26.8424, 13.1027]])\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [1., 0., 0.,  ..., 0., 0., 0.],\n        [1., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 1.],\n        [0., 0., 0.,  ..., 0., 0., 1.],\n        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# converting numpy array into torch tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "outputs = torch.from_numpy(outputs)\n",
    "\n",
    "print(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "121081\n(tensor([[33.2594,  7.0309, 60.8409, 32.7850, 37.2703, 15.6024,  6.7223, 10.1208],\n        [33.3242,  6.5626, 64.7589, 29.3024, 36.9567, 16.0135,  6.0848, 11.4724],\n        [33.7363,  6.5574, 61.5734, 29.1465, 36.2751, 16.4308,  5.7031, 11.6807]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "ds = TensorDataset(inputs,outputs)\n",
    "print(len(ds))\n",
    "print(ds[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(96865, 24216)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_ds, valid_ds = random_split(ds, [96865, 24216])\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1514\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds , batch_size , shuffle=True )\n",
    "val_loader = DataLoader(valid_ds , batch_size)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# defining neural network parameteres\n",
    "input_nodes = 8\n",
    "hidden1_nodes = 64\n",
    "hidden2_nodes = 64\n",
    "output_nodes = 29\n",
    "\n",
    "# creating neural net\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = nn.Linear(input_nodes, hidden1_nodes)\n",
    "        self.hidden1 = nn.Linear(hidden1_nodes, hidden2_nodes)\n",
    "        self.hidden2 = nn.Linear(hidden2_nodes, output_nodes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3240, -0.3149,  0.2502, -0.0680, -0.1624, -0.1805,  0.0922,  0.2043],\n",
       "         [ 0.3253,  0.1093, -0.1586,  0.2853, -0.2684,  0.2492, -0.3181,  0.2410],\n",
       "         [-0.1625,  0.2717,  0.0437, -0.2144,  0.2371,  0.2287, -0.2917,  0.2572],\n",
       "         [-0.2423, -0.2979,  0.2416, -0.0577,  0.0555,  0.1063,  0.0841, -0.3224],\n",
       "         [-0.1589, -0.1051, -0.1374, -0.2988,  0.2353, -0.0671, -0.2655, -0.1007],\n",
       "         [ 0.3374, -0.2397, -0.1125,  0.1530, -0.3396, -0.3357,  0.3272, -0.0732],\n",
       "         [-0.2689, -0.2072, -0.1661,  0.3017,  0.1831,  0.2527,  0.0989,  0.1099],\n",
       "         [ 0.0433, -0.2259,  0.0953,  0.3033,  0.0829, -0.0514, -0.3207,  0.0966],\n",
       "         [ 0.1781,  0.3031,  0.0927,  0.0972, -0.2115, -0.1252, -0.2501, -0.1693],\n",
       "         [ 0.0158, -0.0248,  0.0341,  0.2014, -0.0654, -0.2094,  0.0470,  0.0081],\n",
       "         [ 0.2072,  0.2746, -0.1054, -0.1032, -0.0956,  0.3527,  0.0538, -0.2365],\n",
       "         [ 0.3092, -0.2291, -0.1198,  0.1638,  0.1471,  0.1577,  0.1777,  0.0856],\n",
       "         [ 0.0017,  0.1590, -0.1351, -0.0101,  0.2021, -0.0444, -0.0610, -0.0383],\n",
       "         [ 0.0629,  0.0257, -0.2221,  0.1267,  0.1365,  0.0343, -0.0278,  0.2235],\n",
       "         [-0.0016, -0.2794, -0.1739,  0.2231, -0.1948,  0.0888,  0.2359, -0.3449],\n",
       "         [-0.2595,  0.1985,  0.0021,  0.2228,  0.0080,  0.3275, -0.0800, -0.0498],\n",
       "         [-0.2324,  0.0261,  0.1561,  0.2146,  0.1521,  0.0558, -0.1869, -0.2208],\n",
       "         [ 0.1352, -0.1555, -0.2433,  0.2228,  0.1955, -0.2676,  0.2496, -0.1397],\n",
       "         [-0.1890,  0.0048,  0.0584, -0.1368, -0.1883,  0.0594,  0.0339, -0.3398],\n",
       "         [-0.0129, -0.1688, -0.1064,  0.2994, -0.0773,  0.0448, -0.1987, -0.3509],\n",
       "         [ 0.2375, -0.2610, -0.1853, -0.3008, -0.1447,  0.1367,  0.0505, -0.0591],\n",
       "         [-0.0158,  0.3408,  0.0823,  0.1743,  0.0397,  0.2422,  0.1777,  0.0096],\n",
       "         [ 0.1827,  0.2449,  0.1821, -0.1254, -0.3420,  0.0426, -0.0682, -0.0521],\n",
       "         [-0.1682,  0.2839,  0.0016,  0.2207,  0.1232,  0.1009,  0.3492, -0.0753],\n",
       "         [ 0.0918,  0.0586, -0.2863,  0.0914,  0.1449,  0.1957, -0.0453,  0.1860],\n",
       "         [ 0.0790,  0.0307,  0.0375, -0.3429,  0.1767, -0.0409,  0.0077,  0.3522],\n",
       "         [-0.2674, -0.1494, -0.2343, -0.1610,  0.3397,  0.2181, -0.3496, -0.2051],\n",
       "         [-0.3199,  0.0346, -0.1363, -0.2358,  0.0975,  0.3293, -0.0935, -0.2612],\n",
       "         [-0.0766,  0.0154, -0.0869,  0.1448, -0.3151,  0.0457, -0.1024,  0.0403],\n",
       "         [ 0.0807, -0.2962, -0.1295, -0.0666,  0.0576, -0.0122, -0.1985, -0.2916],\n",
       "         [ 0.0092, -0.1358,  0.0599, -0.3526,  0.2370, -0.3501,  0.2644, -0.3097],\n",
       "         [ 0.3391, -0.0550,  0.2020,  0.0676, -0.0270,  0.0396,  0.1848,  0.3018],\n",
       "         [-0.2522, -0.1552,  0.1303,  0.2507, -0.3418,  0.1139,  0.1742,  0.3217],\n",
       "         [-0.0333, -0.1714, -0.3032, -0.0459, -0.1656,  0.0500,  0.3003, -0.1342],\n",
       "         [-0.3514,  0.2787,  0.0319, -0.2000,  0.1842,  0.0030, -0.1073,  0.1702],\n",
       "         [-0.0862, -0.0114,  0.2563, -0.0033, -0.3477,  0.1423, -0.3046, -0.0277],\n",
       "         [ 0.1435,  0.0932, -0.0125, -0.1332,  0.2299, -0.1508,  0.1228,  0.0189],\n",
       "         [ 0.2173,  0.2899,  0.2659, -0.3150, -0.0133, -0.1288, -0.0755,  0.1674],\n",
       "         [ 0.2443,  0.0546, -0.1494,  0.1894, -0.1331, -0.2863, -0.0473,  0.1332],\n",
       "         [ 0.2393,  0.1278, -0.0221,  0.0996,  0.0155, -0.2717,  0.3391, -0.2498],\n",
       "         [-0.3321, -0.1305, -0.1239, -0.3309,  0.3035,  0.3010, -0.3434, -0.1057],\n",
       "         [-0.1946, -0.2910,  0.2753,  0.2923, -0.1728,  0.2268, -0.3456, -0.3270],\n",
       "         [ 0.0554,  0.0207, -0.2373,  0.2388,  0.2353,  0.1205,  0.2258,  0.0152],\n",
       "         [-0.0892, -0.0209,  0.0137, -0.2909,  0.2489,  0.1875,  0.2071, -0.2288],\n",
       "         [ 0.0904, -0.0995, -0.2279,  0.0069, -0.1124, -0.0008, -0.0662, -0.1180],\n",
       "         [-0.2831, -0.1874,  0.0333, -0.0995,  0.2542, -0.2916,  0.0284, -0.0943],\n",
       "         [-0.0868,  0.2103, -0.0957, -0.2362,  0.2663, -0.2063, -0.1282, -0.1185],\n",
       "         [ 0.3191,  0.0141, -0.3105,  0.2294,  0.0472,  0.2038,  0.3500, -0.0298],\n",
       "         [-0.2140, -0.1631,  0.3365, -0.0014,  0.2477, -0.1775,  0.2654, -0.0919],\n",
       "         [-0.1683, -0.2846,  0.2669,  0.2492,  0.1033, -0.2843, -0.1294,  0.3031],\n",
       "         [-0.2334,  0.1406,  0.0645, -0.2879,  0.2476,  0.1395, -0.2725,  0.3258],\n",
       "         [-0.2535,  0.2722, -0.1289, -0.0840, -0.0768,  0.0769, -0.3392,  0.1195],\n",
       "         [-0.0417,  0.0280,  0.3410, -0.2047, -0.0308, -0.3299,  0.0679, -0.2546],\n",
       "         [-0.2017,  0.1041, -0.2139, -0.1037,  0.1403,  0.0822, -0.1756, -0.1903],\n",
       "         [ 0.3350, -0.3390, -0.0754, -0.2766, -0.1399, -0.1962,  0.2853,  0.2842],\n",
       "         [-0.0004, -0.2431, -0.1199, -0.0581,  0.3258,  0.3515, -0.1562,  0.1087],\n",
       "         [-0.1107, -0.2353,  0.1915,  0.3495, -0.2760,  0.0801, -0.2959, -0.2141],\n",
       "         [ 0.0643,  0.0122, -0.3314, -0.2945,  0.3444,  0.0188,  0.2985, -0.2793],\n",
       "         [-0.1391, -0.1611,  0.2871, -0.0574, -0.2476,  0.1827,  0.1207,  0.3292],\n",
       "         [ 0.1606, -0.1404, -0.2702, -0.0366, -0.2943, -0.1128, -0.0359, -0.0603],\n",
       "         [-0.2969, -0.2674,  0.2970,  0.0042,  0.0072,  0.2130,  0.1917, -0.1023],\n",
       "         [-0.1582, -0.2738, -0.2197, -0.0206, -0.2964,  0.0724, -0.0693, -0.0534],\n",
       "         [-0.3485, -0.1863,  0.1171,  0.2864,  0.3108, -0.0808, -0.1964, -0.3210],\n",
       "         [ 0.0692,  0.0532, -0.1690, -0.0306,  0.3253, -0.2556,  0.1129,  0.1141]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 2.4561e-01,  2.8489e-01,  1.6413e-01, -2.3842e-01, -1.3163e-01,\n",
       "          1.5323e-01,  2.7983e-01, -1.3057e-01, -9.7062e-02, -9.8823e-02,\n",
       "          1.5358e-01,  6.5703e-02, -7.1549e-02, -2.9220e-01,  4.5763e-02,\n",
       "          5.6050e-02, -2.8655e-01, -3.4913e-01, -2.5887e-01, -2.0351e-01,\n",
       "         -6.1558e-02, -8.9436e-02, -3.0681e-01, -1.4963e-01,  2.5018e-01,\n",
       "          3.7835e-02, -8.7315e-02, -2.2899e-01,  1.3497e-01,  1.1466e-01,\n",
       "         -1.2770e-01,  1.6776e-01,  2.3225e-01,  1.1273e-01,  1.1278e-01,\n",
       "          2.2717e-01, -6.0106e-02,  2.2185e-01, -1.4850e-02, -9.4334e-02,\n",
       "          8.6725e-02,  2.3940e-01, -3.0639e-01,  2.8939e-01, -1.4790e-01,\n",
       "          3.2287e-01, -2.2594e-01, -2.6999e-02, -1.6223e-01, -2.8082e-01,\n",
       "          7.3419e-02, -1.8176e-01, -8.3226e-02,  1.6715e-01, -3.5144e-01,\n",
       "          3.2237e-01,  2.9140e-01,  2.8069e-01, -3.1615e-01,  3.4929e-01,\n",
       "         -1.3471e-01, -1.7583e-04,  1.6134e-02, -2.6906e-01],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0674,  0.0240, -0.0176,  ..., -0.0393, -0.0802,  0.0759],\n",
       "         [ 0.0297, -0.0609, -0.1166,  ..., -0.0625,  0.1228,  0.0993],\n",
       "         [-0.0786,  0.0632, -0.0859,  ..., -0.0548,  0.0178,  0.0513],\n",
       "         ...,\n",
       "         [ 0.0351,  0.0718, -0.1019,  ...,  0.0548, -0.0191, -0.0378],\n",
       "         [-0.0970,  0.1197,  0.0498,  ..., -0.0857, -0.0056,  0.0303],\n",
       "         [-0.0490,  0.1218, -0.1200,  ..., -0.0921,  0.0262, -0.0515]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0320,  0.0090, -0.0314,  0.0828, -0.1226, -0.1079,  0.0751,  0.0567,\n",
       "          0.0668,  0.0939, -0.0696, -0.0005, -0.0579, -0.0677,  0.0540,  0.0255,\n",
       "          0.0627, -0.0159, -0.0711,  0.0423,  0.1117, -0.0808, -0.0331,  0.0540,\n",
       "          0.0266,  0.0309, -0.0433, -0.0695,  0.0079, -0.0365, -0.0200, -0.0676,\n",
       "          0.0682, -0.0954,  0.1052,  0.0787, -0.0168,  0.1119,  0.0435,  0.1125,\n",
       "         -0.0688, -0.1153,  0.0536,  0.0498,  0.1098, -0.0250, -0.0190, -0.0963,\n",
       "         -0.1003, -0.0345,  0.1232, -0.0007,  0.0149,  0.1106,  0.0885,  0.0699,\n",
       "         -0.0668,  0.0531,  0.0251,  0.0740,  0.0389,  0.0242, -0.0197,  0.0943],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0268,  0.0031, -0.0207,  ...,  0.1143, -0.0724,  0.1200],\n",
       "         [-0.1229,  0.1111, -0.0007,  ...,  0.0981, -0.0807,  0.0619],\n",
       "         [ 0.0808,  0.0436, -0.0968,  ..., -0.1107,  0.0541, -0.0869],\n",
       "         ...,\n",
       "         [ 0.0860, -0.0241, -0.1038,  ...,  0.0151, -0.0338, -0.0620],\n",
       "         [ 0.0221, -0.0974,  0.0987,  ...,  0.1003,  0.0273,  0.0033],\n",
       "         [-0.1047,  0.0534, -0.0035,  ..., -0.0626,  0.0812, -0.0129]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0301,  0.0191,  0.0451, -0.1112,  0.1235,  0.0976, -0.1055, -0.1003,\n",
       "         -0.0003, -0.0089,  0.0028, -0.0171, -0.0045,  0.0539,  0.1081,  0.0673,\n",
       "          0.1234, -0.0933, -0.0674,  0.1112,  0.1241, -0.1235, -0.0636,  0.0212,\n",
       "         -0.0546,  0.0347,  0.0010,  0.0763, -0.0082], requires_grad=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model = Model()\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_dict={}\n",
    "def train(model,epochs,train_batch,valid_batch,lr,opt_fn=torch.optim.SGD):\n",
    "    opt = opt_fn(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        loss_dict[epoch] = 0\n",
    "        i = 0\n",
    "        for input_part, output_part in train_batch:\n",
    "            i+=1\n",
    "            output = model(input_part)\n",
    "            loss = F.mse_loss(output,output_part)\n",
    "            loss_dict[epoch]+=loss\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            #print(\"Done with {0} part of {1}/{2}\".format(i,epoch,epochs))\n",
    "        loss_dict[epoch]/1514\n",
    "        print(\"For epoch {0} avg_loss = {1}\".format(epoch,loss_dict[epoch]))\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For epoch 0 avg_loss = 50.389747619628906\n",
      "For epoch 1 avg_loss = 45.81378173828125\n",
      "For epoch 2 avg_loss = 42.0672721862793\n",
      "For epoch 3 avg_loss = 37.93685531616211\n",
      "For epoch 4 avg_loss = 35.203330993652344\n",
      "For epoch 5 avg_loss = 32.989620208740234\n",
      "For epoch 6 avg_loss = 31.245086669921875\n",
      "For epoch 7 avg_loss = 29.065706253051758\n",
      "For epoch 8 avg_loss = 26.569211959838867\n",
      "For epoch 9 avg_loss = 24.808650970458984\n",
      "For epoch 10 avg_loss = 23.449010848999023\n",
      "For epoch 11 avg_loss = 22.376672744750977\n",
      "For epoch 12 avg_loss = 21.4033145904541\n",
      "For epoch 13 avg_loss = 20.577421188354492\n",
      "For epoch 14 avg_loss = 19.9847469329834\n",
      "For epoch 15 avg_loss = 19.574384689331055\n",
      "For epoch 16 avg_loss = 19.252090454101562\n",
      "For epoch 17 avg_loss = 18.93763542175293\n",
      "For epoch 18 avg_loss = 18.742631912231445\n",
      "For epoch 19 avg_loss = 18.581336975097656\n",
      "For epoch 20 avg_loss = 18.44355010986328\n",
      "For epoch 21 avg_loss = 18.316221237182617\n",
      "For epoch 22 avg_loss = 18.182170867919922\n",
      "For epoch 23 avg_loss = 18.024747848510742\n",
      "For epoch 24 avg_loss = 17.818195343017578\n",
      "For epoch 25 avg_loss = 17.649709701538086\n",
      "For epoch 26 avg_loss = 17.496044158935547\n",
      "For epoch 27 avg_loss = 17.3553409576416\n",
      "For epoch 28 avg_loss = 17.227733612060547\n",
      "For epoch 29 avg_loss = 17.110923767089844\n",
      "For epoch 30 avg_loss = 17.001506805419922\n",
      "For epoch 31 avg_loss = 16.90460968017578\n",
      "For epoch 32 avg_loss = 16.812732696533203\n",
      "For epoch 33 avg_loss = 16.730266571044922\n",
      "For epoch 34 avg_loss = 16.661752700805664\n",
      "For epoch 35 avg_loss = 16.600061416625977\n",
      "For epoch 36 avg_loss = 16.546066284179688\n",
      "For epoch 37 avg_loss = 16.498193740844727\n",
      "For epoch 38 avg_loss = 16.450448989868164\n",
      "For epoch 39 avg_loss = 16.40554428100586\n",
      "For epoch 40 avg_loss = 16.359346389770508\n",
      "For epoch 41 avg_loss = 16.32058334350586\n",
      "For epoch 42 avg_loss = 16.286514282226562\n",
      "For epoch 43 avg_loss = 16.254470825195312\n",
      "For epoch 44 avg_loss = 16.172332763671875\n",
      "For epoch 45 avg_loss = 14.512523651123047\n",
      "For epoch 46 avg_loss = 14.257112503051758\n",
      "For epoch 47 avg_loss = 14.201173782348633\n",
      "For epoch 48 avg_loss = 14.156591415405273\n",
      "For epoch 49 avg_loss = 14.11494255065918\n",
      "For epoch 50 avg_loss = 13.90773868560791\n",
      "For epoch 51 avg_loss = 13.247429847717285\n",
      "For epoch 52 avg_loss = 12.994842529296875\n",
      "For epoch 53 avg_loss = 12.890708923339844\n",
      "For epoch 54 avg_loss = 12.828165054321289\n",
      "For epoch 55 avg_loss = 12.782452583312988\n",
      "For epoch 56 avg_loss = 12.746257781982422\n",
      "For epoch 57 avg_loss = 12.714862823486328\n",
      "For epoch 58 avg_loss = 12.6878662109375\n",
      "For epoch 59 avg_loss = 12.665401458740234\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "lr = 1e-2\n",
    "\n",
    "history = train(model, epochs, train_loader, val_loader, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 368.925 248.518125\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-10-24T21:39:47.343733</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 368.925 248.518125 \nL 368.925 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 361.725 224.64 \nL 361.725 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m9c86f90ad9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.143182\" xlink:href=\"#m9c86f90ad9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(38.961932 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"93.730239\" xlink:href=\"#m9c86f90ad9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <g transform=\"translate(87.367739 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"145.317296\" xlink:href=\"#m9c86f90ad9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <g transform=\"translate(138.954796 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"196.904353\" xlink:href=\"#m9c86f90ad9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30 -->\n      <g transform=\"translate(190.541853 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"248.49141\" xlink:href=\"#m9c86f90ad9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40 -->\n      <g transform=\"translate(242.12891 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"300.078467\" xlink:href=\"#m9c86f90ad9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50 -->\n      <g transform=\"translate(293.715967 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"351.665524\" xlink:href=\"#m9c86f90ad9\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 60 -->\n      <g transform=\"translate(345.303024 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m7bfa96b309\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7bfa96b309\" y=\"202.523243\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 206.322462)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7bfa96b309\" y=\"176.323621\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 180.122839)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7bfa96b309\" y=\"150.123998\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 153.923217)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7bfa96b309\" y=\"123.924375\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 127.723594)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7bfa96b309\" y=\"97.724753\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 35 -->\n      <g transform=\"translate(7.2 101.523971)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7bfa96b309\" y=\"71.52513\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 40 -->\n      <g transform=\"translate(7.2 75.324349)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7bfa96b309\" y=\"45.325507\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 45 -->\n      <g transform=\"translate(7.2 49.124726)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7bfa96b309\" y=\"19.125884\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 50 -->\n      <g transform=\"translate(7.2 22.925103)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p1340c9dc50)\" d=\"M 42.143182 17.083636 \nL 47.301888 41.061352 \nL 52.460593 60.69278 \nL 57.619299 82.335852 \nL 62.778005 96.659314 \nL 67.93671 108.258991 \nL 73.095416 117.400215 \nL 78.254122 128.820004 \nL 83.412827 141.901446 \nL 88.571533 151.126653 \nL 93.730239 158.251064 \nL 98.888945 163.870035 \nL 104.04765 168.970358 \nL 109.206356 173.297977 \nL 114.365062 176.403546 \nL 119.523767 178.553813 \nL 124.682473 180.24261 \nL 129.841179 181.890331 \nL 134.999884 182.912135 \nL 140.15859 183.757308 \nL 145.317296 184.479301 \nL 150.476002 185.146494 \nL 155.634707 185.848908 \nL 160.793413 186.673793 \nL 165.952119 187.756113 \nL 171.110824 188.638965 \nL 176.26953 189.44416 \nL 181.428236 190.181435 \nL 186.586941 190.850087 \nL 191.745647 191.462162 \nL 196.904353 192.035499 \nL 202.063059 192.543232 \nL 207.221764 193.024661 \nL 212.38047 193.456777 \nL 217.539176 193.815785 \nL 222.697881 194.139042 \nL 227.856587 194.421973 \nL 233.015293 194.672821 \nL 238.173998 194.923 \nL 243.332704 195.158297 \nL 248.49141 195.400371 \nL 253.650116 195.603486 \nL 258.808821 195.782006 \nL 263.967527 195.949911 \nL 269.126233 196.380308 \nL 274.284938 205.077583 \nL 279.443644 206.415918 \nL 284.60235 206.709033 \nL 289.761055 206.942641 \nL 294.919761 207.160878 \nL 300.078467 208.24661 \nL 305.237173 211.706579 \nL 310.395878 213.030117 \nL 315.554584 213.57577 \nL 320.71329 213.903495 \nL 325.871995 214.143025 \nL 331.030701 214.332683 \nL 336.189407 214.49719 \nL 341.348112 214.63865 \nL 346.506818 214.756364 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 361.725 224.64 \nL 361.725 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 361.725 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 361.725 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1340c9dc50\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(list(loss_dict.keys()), list(loss_dict.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'crop_prediction_weights_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('input.weight',\n",
       "              tensor([[-3.2542e-01, -3.1018e-01,  3.3977e-01, -3.2862e-02, -1.9732e-01,\n",
       "                       -1.1428e-01,  1.1619e-01,  2.8608e-01],\n",
       "                      [ 3.5996e-01,  1.3895e-01, -1.4563e-01,  3.6921e-01, -2.2927e-01,\n",
       "                        2.1933e-01, -4.0005e-01,  2.4126e-01],\n",
       "                      [-1.8391e-01,  2.8096e-01,  1.1709e-02, -2.3658e-01,  2.7456e-01,\n",
       "                        2.9811e-01, -3.5366e-01,  3.1016e-01],\n",
       "                      [-2.3667e-01, -3.0875e-01,  2.5648e-01, -1.0824e-01,  1.2827e-01,\n",
       "                        1.4139e-01,  4.6707e-02, -4.7841e-01],\n",
       "                      [-1.5888e-01, -1.0514e-01, -1.3736e-01, -2.9876e-01,  2.3532e-01,\n",
       "                       -6.7131e-02, -2.6553e-01, -1.0066e-01],\n",
       "                      [ 3.5511e-01, -2.3496e-01, -1.0138e-01,  1.6755e-01, -3.3340e-01,\n",
       "                       -3.3512e-01,  3.2877e-01, -7.0164e-02],\n",
       "                      [-1.8500e-01, -1.8730e-01, -1.0319e-01,  3.6101e-01,  2.2619e-01,\n",
       "                        3.5572e-01,  1.0255e-01,  6.8907e-02],\n",
       "                      [ 1.6621e-01, -1.9881e-01,  1.1670e-01,  4.0639e-01,  2.4455e-01,\n",
       "                       -4.6831e-02, -4.9091e-01,  4.3363e-02],\n",
       "                      [ 2.4479e-01,  3.5642e-01,  5.9360e-02,  2.0022e-01, -2.0563e-01,\n",
       "                       -1.4865e-01, -3.1651e-01, -2.2859e-01],\n",
       "                      [-2.6021e-04, -3.0735e-02, -2.2794e-02,  1.9157e-01, -8.2144e-02,\n",
       "                       -2.1280e-01,  1.8715e-02,  2.6499e-02],\n",
       "                      [ 2.3302e-01,  2.7392e-01, -9.6725e-02, -1.1443e-01, -1.4686e-01,\n",
       "                        4.5029e-01,  1.0609e-01, -2.4797e-01],\n",
       "                      [ 3.1332e-01, -2.1864e-01, -1.0183e-01,  2.3246e-01,  1.7224e-01,\n",
       "                        1.3415e-01,  2.1003e-01,  1.0112e-01],\n",
       "                      [ 1.4728e-03,  1.6251e-01, -1.6984e-01, -1.0899e-03,  1.9079e-01,\n",
       "                       -2.2283e-03, -6.2327e-02, -2.9130e-02],\n",
       "                      [ 5.9324e-02,  2.4256e-02, -2.0570e-01,  1.2691e-01,  1.4316e-01,\n",
       "                        5.7391e-02, -2.2012e-02,  2.3722e-01],\n",
       "                      [-1.2116e-03, -2.7831e-01, -1.3748e-01,  2.4257e-01, -1.9193e-01,\n",
       "                        1.1139e-01,  2.5346e-01, -3.4666e-01],\n",
       "                      [-2.5892e-01,  1.8793e-01, -1.4444e-02,  2.2150e-01, -1.5255e-02,\n",
       "                        4.0093e-01, -1.2309e-01, -7.0128e-02],\n",
       "                      [-1.8045e-01,  3.5203e-02,  1.5554e-01,  2.7282e-01,  2.1330e-01,\n",
       "                        5.4371e-02, -3.3573e-01, -3.1214e-01],\n",
       "                      [ 1.3048e-01, -1.5652e-01, -2.6023e-01,  2.2005e-01,  1.8557e-01,\n",
       "                       -2.7272e-01,  2.3887e-01, -1.3961e-01],\n",
       "                      [-1.9051e-01,  4.4310e-03,  4.2108e-02, -1.3832e-01, -1.8984e-01,\n",
       "                        5.5646e-02,  3.3021e-02, -3.4035e-01],\n",
       "                      [-2.1296e-03, -1.6356e-01, -1.1649e-01,  3.1016e-01, -6.8625e-02,\n",
       "                        5.3567e-02, -2.0098e-01, -3.5275e-01],\n",
       "                      [ 2.3639e-01, -2.6126e-01, -1.8624e-01, -3.0165e-01, -1.4550e-01,\n",
       "                        1.3408e-01,  4.9666e-02, -5.9819e-02],\n",
       "                      [ 6.4141e-02,  3.6537e-01,  8.3417e-02,  2.2944e-01,  7.2070e-02,\n",
       "                        2.5428e-01,  2.4747e-01, -1.9553e-02],\n",
       "                      [ 2.0546e-01,  2.6995e-01,  2.0779e-01, -1.3852e-01, -3.4802e-01,\n",
       "                        6.6632e-02, -7.4487e-02, -3.1351e-02],\n",
       "                      [-1.4411e-01,  2.9266e-01, -3.9736e-02,  2.8416e-01,  1.4601e-01,\n",
       "                        8.9521e-02,  4.2496e-01, -1.2788e-01],\n",
       "                      [ 1.1396e-01,  7.2630e-02, -3.3320e-01,  1.2214e-01,  1.5913e-01,\n",
       "                        2.3377e-01, -6.7228e-02,  2.0401e-01],\n",
       "                      [ 7.6237e-02,  1.5686e-02,  5.9340e-02, -3.2755e-01,  2.7031e-01,\n",
       "                       -1.9103e-01, -5.2567e-02,  4.4806e-01],\n",
       "                      [-2.7723e-01, -1.5345e-01, -2.3827e-01, -1.7236e-01,  3.3052e-01,\n",
       "                        1.9993e-01, -3.4964e-01, -2.0513e-01],\n",
       "                      [-3.2626e-01,  3.1189e-02, -1.3394e-01, -2.4441e-01,  9.3233e-02,\n",
       "                        3.1432e-01, -9.7620e-02, -2.6507e-01],\n",
       "                      [-7.6563e-02,  1.5353e-02, -8.6886e-02,  1.4484e-01, -3.1507e-01,\n",
       "                        4.5688e-02, -1.0237e-01,  4.0313e-02],\n",
       "                      [ 8.0702e-02, -2.9622e-01, -1.2952e-01, -6.6647e-02,  5.7610e-02,\n",
       "                       -1.2224e-02, -1.9849e-01, -2.9155e-01],\n",
       "                      [ 4.9993e-02, -1.2743e-01,  2.1653e-01, -3.4629e-01,  3.1166e-01,\n",
       "                       -3.5494e-01,  3.3938e-01, -3.4995e-01],\n",
       "                      [ 3.2621e-01, -6.4833e-02,  2.1743e-01,  5.8120e-02, -3.6504e-02,\n",
       "                        2.3683e-02,  2.3442e-01,  3.7733e-01],\n",
       "                      [-2.7162e-01, -1.5112e-01,  1.8662e-01,  2.5499e-01, -4.2588e-01,\n",
       "                        2.3597e-01,  3.7264e-01,  3.6103e-01],\n",
       "                      [-3.3250e-02, -1.7142e-01, -3.0318e-01, -4.5909e-02, -1.6559e-01,\n",
       "                        4.9974e-02,  3.0032e-01, -1.3424e-01],\n",
       "                      [-3.5410e-01,  2.7729e-01,  1.1189e-02, -2.0269e-01,  1.7827e-01,\n",
       "                        4.4824e-04, -1.1197e-01,  1.6900e-01],\n",
       "                      [-9.7029e-02, -3.6900e-02,  3.0906e-01, -5.1819e-02, -3.7595e-01,\n",
       "                        2.4321e-01, -3.0649e-01, -1.9737e-02],\n",
       "                      [ 1.8441e-01,  1.1235e-01, -1.5027e-02, -8.8796e-02,  2.7206e-01,\n",
       "                       -1.5456e-01,  1.6161e-01,  6.8463e-02],\n",
       "                      [ 2.1057e-01,  2.7762e-01,  3.1807e-01, -3.5723e-01,  4.7763e-02,\n",
       "                       -1.4078e-01, -9.1331e-02,  2.8689e-01],\n",
       "                      [ 2.4573e-01,  5.4836e-02, -1.5219e-01,  1.8900e-01, -1.3487e-01,\n",
       "                       -2.8499e-01, -4.0193e-02,  1.3376e-01],\n",
       "                      [ 2.1948e-01,  1.6532e-01, -1.9309e-02,  1.8888e-01,  3.0691e-02,\n",
       "                       -3.8489e-01,  3.8850e-01, -2.7097e-01],\n",
       "                      [-3.1048e-01, -1.1681e-01, -2.4751e-02, -2.8665e-01,  3.1925e-01,\n",
       "                        4.4721e-01, -3.6278e-01, -9.1410e-02],\n",
       "                      [-1.7686e-01, -2.5962e-01,  3.1208e-01,  3.3534e-01, -1.3192e-01,\n",
       "                        1.6927e-01, -3.4975e-01, -3.8804e-01],\n",
       "                      [ 2.5761e-02,  1.5107e-02, -3.0989e-01,  2.0709e-01,  1.9217e-01,\n",
       "                        1.0353e-01,  2.3572e-01,  1.6574e-02],\n",
       "                      [-5.8064e-02, -2.3953e-02, -4.0225e-02, -3.0566e-01,  2.6384e-01,\n",
       "                        1.9315e-01,  2.2667e-01, -2.9197e-01],\n",
       "                      [ 9.0418e-02, -9.9492e-02, -2.2793e-01,  6.8807e-03, -1.1235e-01,\n",
       "                       -8.2523e-04, -6.6188e-02, -1.1802e-01],\n",
       "                      [-2.6054e-01, -1.9830e-01,  9.2513e-02, -1.0849e-01,  2.7090e-01,\n",
       "                       -3.2156e-01,  1.8791e-02, -8.4362e-02],\n",
       "                      [-8.6774e-02,  2.1032e-01, -9.5709e-02, -2.3624e-01,  2.6630e-01,\n",
       "                       -2.0626e-01, -1.2825e-01, -1.1854e-01],\n",
       "                      [ 3.2107e-01,  6.1530e-03, -2.9564e-01,  2.0937e-01,  7.5738e-02,\n",
       "                        2.8175e-01,  4.0770e-01, -2.7833e-02],\n",
       "                      [-1.4214e-01, -1.4379e-01,  4.0379e-01,  2.9455e-02,  3.5338e-01,\n",
       "                       -1.7906e-01,  3.2127e-01, -1.5294e-01],\n",
       "                      [-1.8870e-01, -2.8895e-01,  2.6556e-01,  2.4724e-01,  1.0149e-01,\n",
       "                       -3.7787e-01, -7.2253e-02,  3.9897e-01],\n",
       "                      [-2.4459e-01,  1.4596e-01,  8.4651e-02, -2.6649e-01,  2.7235e-01,\n",
       "                        1.3848e-01, -3.4695e-01,  4.0581e-01],\n",
       "                      [-2.5351e-01,  2.7215e-01, -1.2894e-01, -8.4026e-02, -7.6757e-02,\n",
       "                        7.6908e-02, -3.3921e-01,  1.1949e-01],\n",
       "                      [-6.0151e-02,  3.5595e-02,  3.6021e-01, -2.2349e-01, -1.0635e-01,\n",
       "                       -4.0421e-01,  9.1414e-02, -3.1305e-01],\n",
       "                      [-2.0231e-01,  1.0379e-01, -2.1422e-01, -1.0457e-01,  1.3949e-01,\n",
       "                        8.0717e-02, -1.7561e-01, -1.9035e-01],\n",
       "                      [ 3.3367e-01, -3.3919e-01, -8.3391e-02, -2.7809e-01, -1.4468e-01,\n",
       "                       -1.9917e-01,  2.7844e-01,  2.8383e-01],\n",
       "                      [ 2.1619e-02, -2.6709e-01, -5.3459e-02, -8.9204e-02,  3.9421e-01,\n",
       "                        4.1202e-01, -2.5421e-01,  1.2915e-01],\n",
       "                      [-7.9737e-02, -2.2407e-01,  1.8022e-01,  3.8313e-01, -3.3645e-01,\n",
       "                        4.6386e-02, -3.7008e-01, -2.1526e-01],\n",
       "                      [ 6.1305e-02,  1.1428e-02, -3.3594e-01, -2.9690e-01,  3.4150e-01,\n",
       "                        1.2349e-02,  2.9381e-01, -2.8088e-01],\n",
       "                      [-1.8830e-01, -1.7342e-01,  3.0323e-01, -7.9755e-02, -2.8158e-01,\n",
       "                        1.9726e-01,  1.6314e-01,  4.2158e-01],\n",
       "                      [ 1.6065e-01, -1.4041e-01, -2.7024e-01, -3.6556e-02, -2.9432e-01,\n",
       "                       -1.1284e-01, -3.5890e-02, -6.0291e-02],\n",
       "                      [-2.8066e-01, -2.7659e-01,  3.6691e-01,  2.0585e-02, -1.4182e-02,\n",
       "                        2.1309e-01,  2.6159e-01, -8.2481e-02],\n",
       "                      [-1.5822e-01, -2.7383e-01, -2.1974e-01, -2.0634e-02, -2.9640e-01,\n",
       "                        7.2374e-02, -6.9304e-02, -5.3406e-02],\n",
       "                      [-3.1601e-01, -1.7693e-01,  1.3900e-01,  3.1822e-01,  3.7610e-01,\n",
       "                       -6.2845e-02, -2.5179e-01, -3.9524e-01],\n",
       "                      [ 5.8909e-02,  5.0751e-02, -1.9535e-01, -3.6650e-02,  3.1098e-01,\n",
       "                       -2.5964e-01,  1.0291e-01,  1.1339e-01]])),\n",
       "             ('input.bias',\n",
       "              tensor([ 2.4731e-01,  2.8819e-01,  1.6291e-01, -2.4029e-01, -1.3163e-01,\n",
       "                       1.5387e-01,  2.8202e-01, -1.2758e-01, -9.1824e-02, -9.9599e-02,\n",
       "                       1.5393e-01,  6.7681e-02, -7.1386e-02, -2.9205e-01,  4.6086e-02,\n",
       "                       5.4357e-02, -2.8803e-01, -3.4925e-01, -2.5890e-01, -2.0306e-01,\n",
       "                      -6.1600e-02, -8.5669e-02, -3.0405e-01, -1.4756e-01,  2.5157e-01,\n",
       "                       3.4171e-02, -8.7757e-02, -2.2939e-01,  1.3497e-01,  1.1466e-01,\n",
       "                      -1.2571e-01,  1.6810e-01,  2.3310e-01,  1.1273e-01,  1.1259e-01,\n",
       "                       2.2456e-01, -5.6399e-02,  2.2074e-01, -1.4812e-02, -9.0626e-02,\n",
       "                       8.7968e-02,  2.4239e-01, -3.0660e-01,  2.9038e-01, -1.4790e-01,\n",
       "                       3.2160e-01, -2.2594e-01, -2.6325e-02, -1.6063e-01, -2.8037e-01,\n",
       "                       7.2257e-02, -1.8176e-01, -8.1915e-02,  1.6712e-01, -3.5140e-01,\n",
       "                       3.1956e-01,  2.9256e-01,  2.8054e-01, -3.1700e-01,  3.4929e-01,\n",
       "                      -1.3475e-01, -1.7583e-04,  1.6561e-02, -2.6938e-01])),\n",
       "             ('hidden1.weight',\n",
       "              tensor([[-0.0323,  0.0114, -0.0011,  ..., -0.0393, -0.0201,  0.0774],\n",
       "                      [ 0.0078, -0.0782, -0.1666,  ..., -0.0625,  0.1212,  0.0980],\n",
       "                      [-0.1139,  0.0510, -0.1165,  ..., -0.0548,  0.0726,  0.0506],\n",
       "                      ...,\n",
       "                      [ 0.0540,  0.1027, -0.1571,  ...,  0.0548,  0.0048, -0.0389],\n",
       "                      [-0.1068,  0.1466,  0.0462,  ..., -0.0857, -0.0156,  0.0309],\n",
       "                      [-0.0745,  0.1354, -0.0944,  ..., -0.0921,  0.0718, -0.0514]])),\n",
       "             ('hidden1.bias',\n",
       "              tensor([ 0.0313,  0.0066, -0.0282,  0.0825, -0.1286, -0.1111,  0.0793,  0.0577,\n",
       "                       0.0687,  0.0897, -0.0676, -0.0026, -0.0579, -0.0632,  0.0471,  0.0255,\n",
       "                       0.0627, -0.0159, -0.0712,  0.0357,  0.1141, -0.0808, -0.0324,  0.0535,\n",
       "                       0.0265,  0.0352, -0.0453, -0.0690,  0.0051, -0.0384, -0.0199, -0.0615,\n",
       "                       0.0706, -0.0952,  0.1052,  0.0737, -0.0185,  0.1137,  0.0429,  0.1163,\n",
       "                      -0.0659, -0.1153,  0.0631,  0.0486,  0.1096, -0.0262, -0.0149, -0.0969,\n",
       "                      -0.1008, -0.0382,  0.1262,  0.0008,  0.0149,  0.1106,  0.0910,  0.0657,\n",
       "                      -0.0671,  0.0615,  0.0290,  0.0785,  0.0437,  0.0306, -0.0179,  0.0982])),\n",
       "             ('hidden2.weight',\n",
       "              tensor([[ 0.0389, -0.0311, -0.0209,  ...,  0.1325, -0.0931,  0.0919],\n",
       "                      [-0.1768,  0.2152,  0.0430,  ...,  0.0673, -0.1338,  0.0258],\n",
       "                      [ 0.0811,  0.0438, -0.0963,  ..., -0.1104,  0.0545, -0.0872],\n",
       "                      ...,\n",
       "                      [ 0.0854, -0.0242, -0.1043,  ...,  0.0144, -0.0338, -0.0621],\n",
       "                      [-0.0710, -0.0794,  0.1771,  ...,  0.1564,  0.0195,  0.1185],\n",
       "                      [-0.1910,  0.0037, -0.0573,  ..., -0.0580,  0.0721, -0.0158]])),\n",
       "             ('hidden2.bias',\n",
       "              tensor([-0.0298,  0.0111,  0.0451, -0.1077,  0.1264,  0.0986, -0.1093, -0.1008,\n",
       "                      -0.0043, -0.0297,  0.0140, -0.0175,  0.0032,  0.0391,  0.1063,  0.0819,\n",
       "                       0.1142, -0.0918, -0.0693,  0.1123,  0.1225, -0.1124, -0.0662,  0.0115,\n",
       "                      -0.0548,  0.0285,  0.0010,  0.0971,  0.0017]))])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('input.weight',\n",
       "              tensor([[ 1.4240e-01,  3.0208e-01,  3.3952e-01,  4.0957e-01, -2.1840e-01,\n",
       "                        7.7345e-02, -1.1007e-01, -6.7018e-02],\n",
       "                      [-1.6411e-01, -3.2685e-01, -3.2188e-02, -1.7808e-01,  2.6823e-01,\n",
       "                       -2.3882e-01,  1.7069e-01,  2.4261e-01],\n",
       "                      [-2.9862e-01,  1.3380e-01,  3.0032e-01,  8.4978e-02, -1.1280e-01,\n",
       "                        3.9817e-01,  3.1366e-01, -8.1339e-02],\n",
       "                      [-3.3819e-01, -7.2151e-02,  2.0203e-01, -3.1742e-01,  1.6309e-01,\n",
       "                       -3.4058e-01,  2.2519e-01,  2.2271e-01],\n",
       "                      [-1.3653e-01,  3.2881e-01, -2.8039e-01, -7.7726e-02, -1.7620e-01,\n",
       "                        7.9638e-02,  2.9207e-01, -2.4837e-01],\n",
       "                      [-2.6533e-01, -2.8714e-01,  2.9645e-02,  2.8596e-01,  2.1628e-01,\n",
       "                        2.1521e-01,  2.7535e-01, -3.3423e-01],\n",
       "                      [ 2.9354e-01, -1.7299e-01, -2.2842e-01,  1.5060e-01, -2.1313e-01,\n",
       "                       -1.2420e-01,  2.3784e-01,  1.7455e-02],\n",
       "                      [ 2.6589e-03, -2.3575e-01, -2.9266e-01,  1.5451e-01, -2.9297e-01,\n",
       "                        9.6555e-03,  4.6425e-02,  1.2983e-01],\n",
       "                      [ 7.8113e-02, -3.5014e-01,  2.0354e-01,  8.9727e-02,  3.4550e-01,\n",
       "                        5.4940e-02, -3.2907e-01,  3.1784e-02],\n",
       "                      [ 8.5027e-02,  3.2266e-01, -2.1427e-01, -1.4585e-01, -1.3510e-01,\n",
       "                        2.3001e-01,  4.6539e-02, -2.3621e-01],\n",
       "                      [ 2.4505e-01,  1.2278e-01, -2.4933e-01,  3.8219e-01,  4.5098e-01,\n",
       "                       -5.6703e-02, -2.0738e-02, -2.7720e-01],\n",
       "                      [ 2.8449e-01, -3.4173e-01,  1.7214e-01,  2.4358e-01, -3.7912e-01,\n",
       "                       -5.6290e-02, -1.8460e-01,  1.6423e-01],\n",
       "                      [-8.0803e-02,  2.2736e-01, -3.2282e-01,  3.0734e-01, -8.4570e-02,\n",
       "                        2.3535e-01, -2.9111e-01,  2.4128e-02],\n",
       "                      [-3.5145e-01,  2.9469e-01, -1.0473e-02, -1.2858e-01, -1.7325e-01,\n",
       "                        2.3049e-01,  3.1718e-01, -6.4269e-02],\n",
       "                      [ 3.1155e-01,  1.8785e-01, -2.7525e-01, -3.2683e-01,  1.3108e-01,\n",
       "                       -4.5039e-02,  7.1295e-02,  1.0590e-01],\n",
       "                      [-1.4149e-02, -5.6659e-02,  2.2329e-01, -5.4066e-02, -1.3932e-01,\n",
       "                        1.6134e-01, -1.8559e-01, -2.7663e-01],\n",
       "                      [ 1.2911e-01,  5.1494e-02,  8.2068e-02, -1.2603e-01, -6.4939e-02,\n",
       "                        2.7277e-01,  4.2378e-02, -1.8285e-01],\n",
       "                      [-3.1099e-01,  1.3142e-01,  2.0098e-01, -1.3360e-01,  2.3552e-02,\n",
       "                       -3.0665e-01,  4.4835e-02,  3.0397e-01],\n",
       "                      [ 2.8312e-01, -3.4624e-01,  4.7223e-02, -3.3249e-01, -2.3504e-01,\n",
       "                        2.7385e-01,  3.2831e-01,  2.2339e-01],\n",
       "                      [-1.9647e-01, -3.1262e-01,  3.7448e-01, -2.3283e-01,  2.9190e-01,\n",
       "                        3.9999e-01,  1.4839e-01,  2.5432e-02],\n",
       "                      [ 3.2453e-01, -1.7407e-01, -2.4976e-01,  1.9212e-01,  3.1824e-01,\n",
       "                        2.0594e-01, -1.4348e-01,  3.0517e-01],\n",
       "                      [ 1.7710e-01, -2.3167e-01, -6.3289e-02,  2.4409e-01,  2.6072e-02,\n",
       "                        3.2994e-01, -2.2519e-01,  3.3582e-01],\n",
       "                      [ 2.0413e-01,  4.8716e-02,  1.2877e-01,  1.7005e-01, -1.1270e-01,\n",
       "                       -3.4320e-01,  9.2843e-02,  2.6733e-01],\n",
       "                      [ 1.3660e-01, -8.6473e-02,  1.3970e-01, -1.1355e-01, -1.2986e-01,\n",
       "                       -2.2345e-01,  2.1543e-01, -2.2261e-01],\n",
       "                      [-1.3919e-01, -1.2147e-01,  3.6175e-01, -7.0732e-03,  3.3509e-01,\n",
       "                        1.5589e-01,  2.1116e-02, -1.4959e-01],\n",
       "                      [ 2.8718e-01, -1.2129e-01,  2.2707e-01,  2.3529e-02,  3.3529e-01,\n",
       "                       -3.6892e-01, -2.8835e-01, -5.6738e-03],\n",
       "                      [-1.0630e-01,  3.3397e-01, -3.0560e-01,  3.3230e-01,  2.5918e-01,\n",
       "                        1.7609e-01,  3.5533e-01,  1.3317e-01],\n",
       "                      [-5.3544e-02,  1.8228e-01,  1.7682e-01,  3.3052e-01,  6.7296e-02,\n",
       "                        2.0060e-01, -4.6851e-01, -3.7490e-01],\n",
       "                      [ 7.3580e-02, -1.5881e-01,  3.7242e-01,  3.9363e-01, -3.1687e-01,\n",
       "                       -1.8624e-01,  2.7052e-01, -2.8958e-01],\n",
       "                      [ 2.1871e-01,  2.6717e-01,  1.0754e-01,  2.2469e-01, -7.2467e-02,\n",
       "                       -5.8409e-02,  2.6826e-01,  2.8667e-01],\n",
       "                      [-2.4402e-01, -2.9252e-01, -6.8823e-02,  1.5803e-01,  3.6501e-01,\n",
       "                        1.6458e-01,  3.8882e-01, -6.6492e-02],\n",
       "                      [-1.3059e-02,  3.1041e-02, -2.3342e-01, -2.2651e-01,  1.9279e-01,\n",
       "                        2.1095e-01, -8.1233e-02,  1.1332e-01],\n",
       "                      [ 3.0436e-01,  1.1376e-01, -3.1887e-01, -3.5339e-01,  2.1493e-01,\n",
       "                       -1.2574e-01, -2.7642e-01,  2.3652e-01],\n",
       "                      [-2.4928e-01,  1.7518e-01,  1.2429e-01,  2.1034e-01, -1.9285e-01,\n",
       "                        2.2077e-01, -3.2459e-01,  3.2868e-01],\n",
       "                      [-3.2679e-01, -1.7558e-01,  6.1477e-02, -2.2173e-01,  1.3136e-01,\n",
       "                        2.5048e-01, -3.0098e-01, -6.5929e-02],\n",
       "                      [-2.6523e-01,  9.6640e-02, -3.3599e-01, -1.4578e-01,  4.5193e-02,\n",
       "                        1.8626e-01, -3.4052e-01, -3.3796e-01],\n",
       "                      [ 1.6688e-01,  3.1369e-01, -2.7203e-01, -3.3376e-01, -1.1129e-02,\n",
       "                        2.7787e-01, -1.7464e-01,  2.5820e-01],\n",
       "                      [-2.9010e-01,  1.8629e-01,  2.5278e-01,  2.3111e-01, -2.6883e-01,\n",
       "                       -1.4575e-01, -1.9943e-01, -3.1558e-01],\n",
       "                      [-2.7100e-01, -4.9177e-02,  1.0142e-01,  5.4107e-02,  4.5620e-02,\n",
       "                        1.5108e-01,  1.6490e-01,  7.9315e-02],\n",
       "                      [ 2.2190e-01, -3.2768e-02,  2.3176e-02,  1.8896e-01, -3.8715e-01,\n",
       "                        5.4354e-02,  3.5764e-01, -1.5883e-01],\n",
       "                      [ 1.8485e-01,  2.4250e-01,  1.4479e-01, -5.2998e-02,  3.4914e-03,\n",
       "                       -1.2099e-01, -1.3709e-01, -4.2240e-01],\n",
       "                      [ 3.8283e-02,  2.6796e-01,  6.2880e-02,  3.7564e-02,  8.6948e-03,\n",
       "                       -2.7683e-01,  1.4914e-02,  2.3113e-01],\n",
       "                      [ 7.1803e-02,  1.7245e-01, -6.5713e-02,  2.0823e-01,  1.5971e-02,\n",
       "                       -2.5547e-01, -1.3505e-01, -1.9164e-01],\n",
       "                      [ 2.5191e-01, -2.7316e-02,  3.0647e-01,  1.2887e-01, -3.8865e-01,\n",
       "                       -9.8361e-02, -3.9169e-03, -2.8961e-02],\n",
       "                      [-2.5474e-01, -1.2103e-02,  6.3302e-02, -3.4051e-01, -2.2493e-01,\n",
       "                       -2.8006e-01, -2.7011e-01,  1.7227e-01],\n",
       "                      [-1.8457e-01,  1.5206e-01, -1.2869e-01,  2.0489e-02, -2.6576e-01,\n",
       "                        9.1884e-02, -2.3830e-01, -2.9322e-01],\n",
       "                      [-2.0632e-01, -1.8689e-01,  2.6278e-01, -3.2214e-01,  8.6991e-02,\n",
       "                       -3.7381e-01,  3.2853e-01, -4.7730e-02],\n",
       "                      [ 2.7897e-01,  2.3755e-01, -1.7298e-03, -3.5956e-02, -4.0767e-01,\n",
       "                        2.3393e-01,  1.7414e-01,  3.2188e-01],\n",
       "                      [-9.0364e-02, -2.4558e-01,  3.5426e-02,  1.9119e-01,  2.8196e-01,\n",
       "                       -3.8903e-01,  3.1892e-01, -1.1739e-01],\n",
       "                      [ 1.9904e-01, -3.0322e-01, -2.3624e-01,  2.9491e-01,  4.4340e-02,\n",
       "                        1.3812e-01, -3.0831e-02,  2.3630e-01],\n",
       "                      [-7.2031e-02, -3.2603e-01, -1.5851e-01,  2.6882e-01,  2.0769e-02,\n",
       "                       -6.8604e-02, -8.8316e-02,  8.9982e-04],\n",
       "                      [ 1.8432e-01,  1.0798e-01, -9.4132e-02,  1.6111e-01,  1.5177e-01,\n",
       "                        3.7928e-01, -1.2328e-01, -3.9921e-01],\n",
       "                      [ 1.7192e-01, -1.1539e-01, -3.0341e-01,  2.0377e-01,  1.8632e-01,\n",
       "                        1.7588e-02, -3.2047e-01,  1.2105e-01],\n",
       "                      [-2.3737e-01,  1.7700e-01,  1.0430e-01,  2.0157e-01, -2.4299e-01,\n",
       "                       -2.1813e-01,  2.6657e-01,  1.6509e-01],\n",
       "                      [-1.3859e-01,  2.1819e-01,  3.1393e-01,  2.7897e-02, -2.3338e-01,\n",
       "                       -2.5321e-01, -2.2650e-02, -3.3400e-01],\n",
       "                      [ 3.0648e-01, -3.0164e-01, -6.2389e-02,  1.3987e-01, -2.8120e-01,\n",
       "                        4.0974e-01,  3.0965e-01,  3.3536e-01],\n",
       "                      [-2.1000e-01,  3.2076e-01,  2.3667e-01,  2.1717e-02, -3.6301e-02,\n",
       "                       -2.6302e-01,  3.4149e-01, -1.7640e-01],\n",
       "                      [ 3.2111e-02, -2.4993e-01, -4.9189e-02,  3.3237e-01,  7.8668e-02,\n",
       "                       -2.6746e-01, -4.0974e-02,  9.1779e-02],\n",
       "                      [ 1.5217e-01, -3.3670e-01, -8.4497e-02,  3.4645e-01, -2.1971e-01,\n",
       "                       -2.2276e-01,  2.2474e-01,  2.9539e-01],\n",
       "                      [-3.7468e-02,  1.2798e-01,  1.0940e-01, -6.8459e-02, -2.7274e-01,\n",
       "                       -2.6102e-01, -2.9084e-01,  1.2440e-01],\n",
       "                      [ 2.7379e-01, -1.1980e-01,  2.4839e-01, -3.0727e-01,  4.5219e-01,\n",
       "                        1.6663e-01, -7.2373e-02,  6.9790e-02],\n",
       "                      [-2.7292e-01, -9.2614e-02,  2.4592e-01, -1.2056e-01,  1.3145e-01,\n",
       "                       -8.8693e-02, -2.7771e-01, -3.0931e-01],\n",
       "                      [-1.9597e-01,  1.5920e-01,  8.4127e-02,  3.0504e-01,  1.7131e-01,\n",
       "                       -2.2892e-01,  3.5955e-01, -3.1694e-01],\n",
       "                      [ 1.8318e-01,  2.6741e-01, -8.1156e-02,  4.0497e-04,  1.2991e-01,\n",
       "                       -7.3469e-02, -3.2383e-02,  3.9939e-01]])),\n",
       "             ('input.bias',\n",
       "              tensor([ 0.2941, -0.0799,  0.1280, -0.1956, -0.1107,  0.3220,  0.1479,  0.1670,\n",
       "                      -0.2371, -0.2083, -0.1401,  0.0170,  0.1307,  0.1765,  0.1371, -0.3100,\n",
       "                      -0.0076, -0.2627,  0.3165,  0.1773,  0.0164,  0.0106,  0.1997, -0.1731,\n",
       "                       0.0285,  0.2929,  0.0253, -0.3077, -0.1535,  0.0208, -0.2103, -0.0501,\n",
       "                      -0.0378, -0.2279, -0.0216,  0.3034, -0.3316,  0.1552, -0.0743,  0.1736,\n",
       "                       0.0817, -0.2727,  0.2772, -0.3124,  0.2021, -0.3382, -0.2015,  0.2622,\n",
       "                      -0.0081,  0.0797,  0.1528,  0.2474, -0.2514, -0.1594,  0.2204, -0.2160,\n",
       "                       0.1267, -0.2843, -0.1900,  0.0559, -0.3175, -0.1287,  0.3001,  0.2452])),\n",
       "             ('hidden1.weight',\n",
       "              tensor([[ 0.1317,  0.1041,  0.0507,  ...,  0.0642,  0.1762, -0.0729],\n",
       "                      [ 0.0115,  0.1022, -0.0746,  ..., -0.0462, -0.0398, -0.0670],\n",
       "                      [ 0.0086,  0.0023, -0.0725,  ..., -0.0598, -0.0778,  0.1119],\n",
       "                      ...,\n",
       "                      [ 0.0718, -0.0836, -0.0881,  ...,  0.1239, -0.0205, -0.0419],\n",
       "                      [ 0.0353, -0.0869, -0.1308,  ..., -0.0697,  0.0790, -0.0519],\n",
       "                      [-0.1535,  0.0661, -0.1263,  ...,  0.1270,  0.0762, -0.0231]])),\n",
       "             ('hidden1.bias',\n",
       "              tensor([-0.0837,  0.0528,  0.0471, -0.0330, -0.0937,  0.0228,  0.0784,  0.0476,\n",
       "                       0.0753, -0.0720,  0.1030, -0.1250, -0.0274,  0.0541,  0.0077,  0.1243,\n",
       "                       0.1107,  0.1078, -0.0186,  0.0836,  0.0611,  0.1095,  0.0335, -0.1057,\n",
       "                      -0.0592,  0.1089, -0.1088,  0.0305,  0.1072,  0.0276,  0.0150, -0.0728,\n",
       "                       0.1230,  0.1081, -0.0007, -0.0325, -0.0560, -0.0682,  0.1041, -0.1077,\n",
       "                      -0.0477,  0.0168, -0.1245,  0.0220, -0.1180,  0.1093,  0.0417, -0.0987,\n",
       "                      -0.0869, -0.1038, -0.0975, -0.1265, -0.0021,  0.0685,  0.0409,  0.0333,\n",
       "                       0.0489, -0.0657, -0.0154,  0.0537, -0.1195, -0.1181, -0.0955, -0.1165])),\n",
       "             ('hidden2.weight',\n",
       "              tensor([[-0.0340,  0.1065,  0.0687,  ...,  0.0448,  0.1381, -0.0038],\n",
       "                      [ 0.1607,  0.1102,  0.1083,  ...,  0.0186, -0.0368,  0.0495],\n",
       "                      [-0.0215, -0.0338, -0.1230,  ...,  0.1032, -0.1062, -0.0847],\n",
       "                      ...,\n",
       "                      [-0.1179,  0.0893, -0.0299,  ..., -0.0110,  0.0177, -0.0288],\n",
       "                      [ 0.2045,  0.0459,  0.0515,  ...,  0.0153,  0.1197, -0.0975],\n",
       "                      [-0.0330, -0.1127,  0.0100,  ..., -0.0373,  0.0511,  0.0419]])),\n",
       "             ('hidden2.bias',\n",
       "              tensor([-0.0032, -0.0048, -0.0440,  0.0457, -0.1178, -0.0296,  0.0782,  0.0486,\n",
       "                      -0.0228,  0.0174,  0.1298,  0.1050,  0.0650,  0.1036,  0.0774, -0.0513,\n",
       "                      -0.0483, -0.0956,  0.1031, -0.0412,  0.0947,  0.0521, -0.0196,  0.0360,\n",
       "                       0.0811,  0.0158,  0.0629,  0.0983, -0.0589]))])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model2 = Model()\n",
    "model2.load_state_dict(torch.load('crop_prediction_weights.pth'))\n",
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1.1137e-03, 1.0728e-04, 4.4431e-06, 9.9732e-07, 3.2659e-02, 1.3428e-02,\n         3.3147e-01, 1.3052e-03, 2.6530e-04, 3.1458e-04, 9.3813e-04, 2.3722e-02,\n         2.4871e-01, 1.7424e-02, 5.0516e-04, 1.7932e-02, 1.7657e-03, 5.1582e-07,\n         1.3871e-01, 5.3930e-02, 1.2608e-05, 7.1804e-07, 4.4971e-03, 7.4200e-02,\n         5.7790e-04, 3.1376e-03, 1.7156e-06, 3.3251e-02, 1.7217e-05]],\n       grad_fn=<SoftmaxBackward>)\nCrop:- arhar  Probab:- 0.11136536300182343\nCrop:- bajra  Probab:- 0.010728138498961926\nCrop:- barley  Probab:- 0.00044431290007196367\nCrop:- coriander  Probab:- 9.973191481549293e-05\nCrop:- cotton  Probab:- 3.265881061553955\nCrop:- cowpea  Probab:- 1.342787742614746\nCrop:- dry chillies  Probab:- 33.14677047729492\nCrop:- garlic  Probab:- 0.13052260875701904\nCrop:- ginger  Probab:- 0.0265301875770092\nCrop:- gram  Probab:- 0.031458210200071335\nCrop:- groundnut  Probab:- 0.09381312131881714\nCrop:- jowar  Probab:- 2.3722035884857178\nCrop:- linseed  Probab:- 24.871213912963867\nCrop:- maize-k  Probab:- 1.742421269416809\nCrop:- maize-r  Probab:- 0.050515513867139816\nCrop:- masoor  Probab:- 1.7932209968566895\nCrop:- moong  Probab:- 0.17656825482845306\nCrop:- onion  Probab:- 5.15821848239284e-05\nCrop:- peas&beans  Probab:- 13.870890617370605\nCrop:- potato  Probab:- 5.393012046813965\nCrop:- ragi  Probab:- 0.0012608444085344672\nCrop:- rapeseed  Probab:- 7.180419925134629e-05\nCrop:- rice  Probab:- 0.4497118294239044\nCrop:- safflower  Probab:- 7.419954776763916\nCrop:- sugarcane  Probab:- 0.05778980627655983\nCrop:- sunflower  Probab:- 0.3137584924697876\nCrop:- turmeric  Probab:- 0.00017156045942101628\nCrop:- urad  Probab:- 3.3250536918640137\nCrop:- wheat  Probab:- 0.001721650012768805\n"
     ]
    }
   ],
   "source": [
    "crops = ['arhar', 'bajra', 'barley', 'coriander', 'cotton', 'cowpea', 'dry chillies', 'garlic', 'ginger', 'gram', 'groundnut', 'jowar', 'linseed', 'maize-k', 'maize-r', 'masoor', 'moong', 'onion', 'peas&beans', 'potato', 'ragi', 'rapeseed', 'rice', 'safflower', 'sugarcane', 'sunflower', 'turmeric', 'urad', 'wheat']\n",
    "\n",
    "\n",
    "pred_user = model2(torch.from_numpy(np.array([[20, 7.4, 78, 23, 28, 15, 18, 5]], dtype='float32')))\n",
    "print(pred_user)\n",
    "\n",
    "greater_than_zero={}\n",
    "index = -1\n",
    "\n",
    "for i in pred_user:\n",
    "    for p in i:\n",
    "        index+=1\n",
    "        if(p > 0):\n",
    "            greater_than_zero[crops[index]] = p \n",
    "    for i in greater_than_zero:\n",
    "        print(\"Crop:- {0}  Probab:- {1}\".format(i,greater_than_zero[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}